# SendMy

[Send My: Arbitrary data transmission via Apple's Find My network](https://positive.security/blog/send-my)

é€šè¿‡Apple's Find My networkä¼ è¾“Arbitrary data



* It's possible to **upload arbitrary data** from **non-internet-connected devices** by sending Find My BLE **broadcasts to nearby Apple devices** that then **upload the data for you**

é™„è¿‘çš„Appleè®¾å¤‡ç»„ä»¶æˆFind Myç½‘ç»œï¼Œé€šè¿‡BLEå¹¿æ’­èƒ½å°†**Arbitrary Data**ç”±æœªè¿æ¥çš„è®¾å¤‡**ä¸Šä¼ **ã€‚

* We released an **ESP32 firmware** that turns the micocontroller into an (upload only) modem, and a **macOS application** to retrieve, decode and display the uploaded data: https://github.com/positive-security/send-my

Positive-securityå‘å¸ƒESP32å›ºä»¶ï¼ˆæ¨¡æ‹ŸAirTagï¼‰ï¼Œè¿˜å‘å¸ƒä¸€ä¸ªmacOS applicationç”¨æ¥è§£æã€è§£ç å’Œå±•ç¤ºä¸Šä¼ çš„æ•°æ®ã€‚

* Being inherent to the privacy and security-focused design of the Find My Offline Finding system, it seems **unlikely that this misuse can be prevented completely**

Find My Offline Finding Systemä»¥å®‰å…¨éšç§ä¸ºè®¾è®¡æ ¸å¿ƒï¼ŒOffline Systemæ»¥ç”¨çœ‹èµ·æ¥ä¸èƒ½è¢«å®Œå…¨é˜»æ­¢ã€‚

<img src="send_my_1_architure.png">



## Introduce

With the recent release of Apple's AirTags, I was curious whether Find My's Offline Finding network could be (ab)used to upload arbitrary data to the Internet, from devices that are not connected to WiFi or mobile internet. The data would be broadcasted via Bluetooth Low Energy and picked up by nearby Apple devices, that, once they are connected to the Internet, forward the data to Apple servers where it could later be retrieved from. Such a technique could be employed by small sensors in uncontrolled environments to avoid the cost and power-consumption of mobile internet. It could also be interesting for exfiltrating data from Faraday-shielded sites that are occasionally visited by iPhone users.

Find My Offline Finding networkç”¨äºï¼ˆä¸èƒ½è¿æ¥wifiæˆ–ç§»åŠ¨æ•°æ®ç½‘ç»œçš„ï¼‰è®¾å¤‡ä¸Šä¼ Arbitrary Dataçš„åœºæ™¯ã€‚æ•°æ®é€šè¿‡BLEå¹¿æ’­æ•£æ’­ï¼Œç”±é™„è¿‘çš„Apple devicesæ”¶é›†ï¼Œä¸€æ—¦è¿™äº›Apple devicesè¿ä¸Šç½‘ç»œï¼Œéšåå‘Apple serverä¸Šä¼ ã€‚Offlineè®¾å¤‡ä¸ä»…å¯ä»¥æŒ‡**ä¸¢å¤±è®¾å¤‡**ï¼Œè¿˜å¯èƒ½æ˜¯æŒ‡**Nearby Devices**ï¼Œè¿™äº›æŠ€æœ¯éƒ½ä¾èµ–äºä¸€é¢—è„±ç¦»â€œå¤§æ ¸â€çš„â€œå°sensorâ€ï¼ˆèŠ‚èƒ½ï¼‰ã€‚IPhoneä¸AirTagséƒ½é…å¤‡è¿™æ ·çš„â€œå°sensorâ€ã€‚

In theory this should be possible: If you can emulate two AirTags, you can encode data by activating only one of the two AirTags at a specific point in time. The receiving device could then check which AirTag is active at what time and decode this back to the original data. However, such a scheme seems highly unreliable and probably unusable in real-world situations due to its very low bandwidth (especially with [restriction such as 16 AirTags per Apple ID](https://9to5mac.com/guides/airtag/) it seemed like data transfer could be limited to only a few bits per hour).

å³ä½¿èƒ½æ¨¡æ‹Ÿä¸¤ä¸ªAirTagsï¼Œä½†åŒä¸€æ—¶åˆ»åªèƒ½é€šè¿‡ç¼–ç æ¿€æ´»å…¶ä¸­ä¸€ä¸ªã€‚Receiving devicesèƒ½å¤Ÿæ£€æŸ¥å‡ºå·²æ¿€æ´»AirTagçš„æ¿€æ´»æ—¶é—´ä¸è§£ç å‡ºåŸå§‹æ•°æ®ã€‚ï¼ˆæ²¡çœ‹æ‡‚è¿™æ®µè¡¨è¾¾çš„æ˜¯ä»€ä¹ˆæ„æ€ï¼‰

Therefore, the feasibility of the idea depends on the system's design and implementation. It turned out that security and privacy decisions in the design of the Offline Finding mechanism make our "use case" quite efficient and almost impossible to protect against.

å› æ­¤ï¼Œideaçš„å¯è¡Œæ€§å–å†³äºç³»ç»Ÿçš„è®¾è®¡ä¸å®ç°ã€‚è¯æ˜äº†Offline Finding mechanismçš„éšç§å®‰å…¨è®¾è®¡ä½¿å¾—æˆ‘ä»¬çš„â€œç”¨ä¾‹â€ååˆ†æœ‰æ•ˆï¼Œå‡ ä¹ä¸å¯èƒ½é˜²èŒƒã€‚ï¼ˆå‡çš„Apple devicesåˆ©ç”¨äº†è¯¥Offline Findingç½‘ç»œï¼Œä¹Ÿæ— æ³•è¢«Appleä¾¦æŸ¥å‡ºï¼Ÿï¼‰

## Offline Finding network description

Thanksfully, the protocol has already been extensively reverse engineered by a group of TU Darmstadt, that published the paper ["Who Can *Find My* Devices?](https://arxiv.org/pdf/2103.02282.pdf)" in March 2021 and released a proof-of-concept open source implementation called [OpenHaystack](https://github.com/seemoo-lab/openhaystack), which allows you to create your own accessories that are tracked by Apple's Find My network. Huge credits to the team! Their work made this possible and both our PoC firmware and the Mac application are based on OpenHaystack.

Apple Find My Networkçš„åè®®å·²ç»è¢«ç ´è§£ä¸”å‘å¸ƒï¼Œå…¶å®ç°åœ¨Githubä¸Šä¹Ÿæœ‰å¯¹åº”çš„é¡¹ç›®OpenHaystackï¼ˆå¯ä»¥è‡ªå®šä¹‰åˆ›å»ºé…ä»¶ï¼Œä»è€Œåˆ©ç”¨Find My Networkè¿›è¡Œè¿½è¸ªï¼‰ï¼Œç‰›æ‰¹å‘€ï¼

A bit simplified, the Find My Offline Finding system works like this:

1. When paring an AirTag with an Apple Device, an Elliptic Curve key pair is collaboratively generated with the public key remaining on the AirTag (and a shared secret to generate rolling public keys)

å½“AirTagä¸Apple DeviceåšPairingæ—¶ï¼Œç”Ÿæˆæ¤­åœ†æ›²çº¿ç§˜é’¥å¯¹ï¼Œå…¶ä¸­å…¬é’¥ä¿å­˜åœ¨AirTagä¸­ï¼ŒåŒæ—¶è¿˜æœ‰ä¸€ä¸ªå…±äº«ç§˜é’¥ï¼Œç”¨æ¥è½®æ¢å…¬é’¥ã€‚

2. Every 2 seconds, the AirTag sends a Bluetooth Low Energy broadcast with the public key as content (changes every 15 minute deterministically using the previously shared secret)

AirTagæ¯éš”2ç§’å‘å‡ºä¸€æ¬¡BLEå¹¿æ’­ï¼ˆæŠ¥æ–‡ä¸­åŒ…å«äº†å…¬é’¥ï¼‰ï¼Œå…¬é’¥æ¯éš”15minä¼šè½®æ¢ä¸€æ¬¡ï¼Œè®¡ç®—éœ€è¦å…±äº«ç§˜é’¥çš„å‚ä¸ã€‚

3. Nearby iPhones, Macbooks, etc. recognize the Find My broadcast, retrieve their current location, encrypt the location with the broadcasted public key (using [ECIES](https://iacr.org/archive/pkc2003/25670211/25670211.pdf)) and upload the encrypted location report

Nearby Devicesåœ¨è¯†åˆ«åˆ°Find Myçš„BLEå¹¿æ’­åï¼Œè·å–è‡ªèº«çš„ä½ç½®ä¿¡æ¯ï¼Œåªæœ‰å¹¿æ’­ä¸­çš„å…¬é’¥è¿›è¡ŒECIESåŠ å¯†ï¼Œç„¶åä¸Šä¼ å¯†æ–‡æŠ¥å‘Šã€‚

4. During device search, the paired Owner Device generates the list of the rolling public keys that the AirTag would have used in the last days and queries an Apple service for their SHA256 hashes. The Apple backend returns the encrypted location reports for the requested key ids

Owner Deviceç”Ÿæˆè½®æ¢å…¬é’¥çš„åˆ—è¡¨ï¼Œé¢„æœŸAirTagä¹Ÿä¼šä½¿ç”¨è¿™äº›ï¼ŒæŸ¥è¯¢æ—¶ä¼šå°†å…¬é’¥çš„SHA256 hasheså‘Šè¯‰Apple Serverå¹¶è¿›è¡Œæ¯”å¯¹ï¼ŒApple Serverå°†æ ¹æ®è¿™äº›hasheså€¼è¿”å›ä½ç½®æŠ¥å‘Šçš„å¯†æ–‡

5. The Owner Device decrypts the location reports and shows an approximate location



<img src="send_my_2_overview.png">



This quite elegant design comes with a few security properties, including:

* Tracking protection against nearby adversaries via rolling public keys

é€šè¿‡è½®æµå…¬é’¥ä¿æŠ¤é™„è¿‘å¹¿æ’­è®¾å¤‡çš„è¡Œè¸ªï¼ˆç±»ä¼¼BLEå¹¿æ’­åœ°å€çš„éšæœºåŒ–ï¼‰

* No access for Apple to user locations

æ— æ³•å‘Appleè¯»å–ç”¨æˆ·ä½ç½®

However, most interestingly for us, Apple does not know which public keys belong to your AirTag, and therefore which location reports were intended for you. This means the endpoint to request location reports for a specific key id does not perform any authorization (but you need to be authenticated with any Apple ID to access the endpoint).

Appleä¹Ÿæ— æ³•çŸ¥é“å“ªä¸ªå…¬é’¥å±äºä½ çš„AirTagï¼Œå› æ­¤ä¹Ÿä¸çŸ¥é“å“ªä»½ä½ç½®æŠ¥å‘Šå±äºä½ ã€‚è¿™æ„å‘³ç€ç»ˆç«¯è¯·æ±‚ä½ç½®æŠ¥å‘Šæ—¶ä¸ä¼šå¯¹Key Idæœ‰ä»»ä½•è®¤è¯ï¼Œå‰ææ˜¯ç»è¿‡Apple Idçš„ç™»å½•è®¤è¯ã€‚

The security solely lies in the encryption of the location reports: The location can only be decrypted with the correct private key, which is infeasible to brute force and only stored on the paired Owner Device.

å®‰å…¨æ€§ä»…å­˜åœ¨äºä½ç½®æŠ¥å‘Šçš„æœºå¯†æ€§ï¼Œå› ä¸ºä½ç½®æŠ¥å‘Šåªä¼šè¢«æ­£ç¡®çš„ç§é’¥ï¼ˆä»…ä¿å­˜åœ¨æœ¬åœ°ï¼Œä¸ä¼šè¢«æš´å‡»æ”»å‡»ï¼‰è§£å¯†ã€‚

## Designing a data exfiltration protocol

From this it seems that the only field that we can use to encode data is the broadcasted EC public key (e.g. we can't influence the GPS coordinates as those are added by the Finding device).

å”¯ä¸€èƒ½è¢«ç”¨ä½œåŠ å¯†ç§˜é’¥çš„å°±æ˜¯BLEå¹¿æ’­ä¸­çš„ECå…¬é’¥ã€‚

For the next section, let's treat the Apple backend as a shared, public key-value store with SHA256 hashes as key, and encrypted location reports as value, with basic operations:

 Apple Serverä»¥Key-Valueçš„å½¢å¼ä¿å­˜ä½ç½®æŠ¥å‘Šï¼Œå…¬é’¥çš„SHA256ä½œä¸ºKeyï¼Œä½ç½®æŠ¥å‘Šçš„å¯†æ–‡ä½œä¸ºValueã€‚ä¸”æä¾›åŸºæœ¬æ“ä½œï¼š

* We can probe whether location reports for a specific SHA256 hash exist or not

ProbeæŸä¸ªç‰¹å®šSHA256ä¸ºKeyçš„Valueæ˜¯å¦å­˜åœ¨

* We can add location reports to a specific SHA256 hash by broadcasting the corresponding public key

æ ¹æ®ç‰¹å®šSHA256å€¼æ·»åŠ ä½ç½®æŠ¥å‘Š

I guess you can already see where this is going: We can set arbitrary bits in the shared key-value store and query them again. If both the sender and receiver agree on an encoding scheme, we can transfer arbitrary data.

æ˜¾ç„¶ï¼Œæˆ‘ä»¬å®Œå…¨å¯ä»¥Set Arbitrary Bitsåˆ°Apple Serverä¸­ï¼Œå†å»è®¿é—®æ•°æ®ã€‚å¦‚æœSenderä¸Recieverå•†é‡å¥½ç¼–ç Schemeï¼Œæˆ‘ä»¬å¯ä»¥åˆ©ç”¨Find My Networkæ¥ä¼ è¾“Arbitrary Dataã€‚

I set out to build a modem that takes a message via the serial interface and then sends out this data in a loop until a new message is received. To ensure we can differentiate a "0"-bit from an unset bit, we will broadcast a different public key depending on the bit value and will query both possible public keys on the receiving side.

æˆ‘å¼€å§‹æ‰“é€ ä¸€æ¬¾Modemï¼Œå¥¹å¯ä»¥é€šè¿‡ä¸²å£æ¥æ”¶æ¶ˆæ¯ï¼Œå¹¶é€šè¿‡BLEå¹¿æ’­å¾ªç¯å‘é€è¯¥æ•°æ®ç›´åˆ°æœ‰æ–°çš„æ¶ˆæ¯è¿‡æ¥ã€‚ç¡®ä¿èƒ½å¤ŸåŒºåˆ†å¼€**0-bit**è·Ÿ**ä¸ºè®¾ç½®bit**ï¼ŒSenderä¼šå¹¿æ’­ä¸åŒçš„å…¬é’¥ï¼ŒRecieverä¼šåŒæ—¶æŸ¥è¯¢å¤šä¸ªå…¬é’¥ã€‚ï¼ˆä¸ºä»€ä¹ˆè¿™æ ·åšä¼šåŒºåˆ†å¼€0-bitè·Ÿunset-bitï¼Ÿä¸ºä»€ä¹ˆè¦åŒºåˆ†å¼€ï¼Ÿï¼‰

There is no guarantee as to when or whether at all specific broadcasts are uploaded to the Apple backend as location reports. This is because some packets might not reach any Apple device and the Finding devices can have highly variable delays between receiving a broadcast and uploading the location report, e.g. depending on their upstream connectivity or power mode. This means our data encoding must be independent of the ordering in which location reports are received, and able to recover partial data streams when some bits are missing entirely. To achieve this, I decided to encode a single bit of data per broadcast together with an index value indicating which bit of the message is being set. Additional message and modem IDs allow the system to be reused for multiple messages and by multiple users.

æ²¡æœ‰æœºåˆ¶ä¿è¯æŒ‡å®šBLEå¹¿æ’­åœ¨ä»€ä¹ˆæ—¶é—´ä¼šä¸Šä¼ ä½ç½®æŠ¥å‘Šï¼Œä¹Ÿä¸ä¿è¯æ˜¯å¦ä¼šä¸Šä¼ ã€‚å› ä¸º**ä¸¢å¤±é…ä»¶**çš„å¹¿æ’­ä¸ä¸€å®šèƒ½æ‰¾åˆ°Finding Deviceï¼Œå†µä¸”Finding Deviceå¯èƒ½ä»æ¥æ”¶åˆ°BLEå¹¿æ’­åˆ°ä¸Šä¼ ä½ç½®æŠ¥å‘Šä¹‹é—´å­˜åœ¨é•¿å»¶æ—¶ï¼Œè¿™å–å†³äºFinding Deviceçš„è¿æ¥æƒ…å†µæˆ–ç”µæºæ¨¡å¼ã€‚è¿™æ„å‘³ç€åŠ å¯†æ•°æ®èƒ½å¤Ÿç‹¬ç«‹è§£å¯†ï¼Œä¸ä¾èµ–äºæ¥æ”¶ç«¯å¯¹æ•°æ®çš„æ¥æ”¶é¡ºåºï¼Œå¹¶ä¸”åœ¨æœ‰bitsæ•°æ®ä¸¢å¤±æ—¶ï¼Œèƒ½å¤Ÿæ¢å¤éƒ¨åˆ†çš„æ•°æ®æµã€‚ä¸ºäº†å®ç°å¥¹ï¼Œå¯¹æ¶ˆæ¯åŠ ä¸Šåºåˆ—å·å¹¶ä¸”è¿›è¡ŒåŠ å¯†ã€‚é¢å¤–çš„ä¿¡æ¯å’ŒModem IDä½¿å¾—ç³»ç»Ÿå¯æ”¯æŒå¤šç”¨æˆ·å¤šæ¶ˆæ¯ã€‚

So when sending a specific bit, we create a 28-byte array of the form "[4b bit index] [4b message ID] [4b modem ID] [padding 0s...] [bit value]", treat this as the public key and send BLE advertisements to e.g. broadcast the information "bit 0 of message 0 is 1".

æˆ‘ä»¬åˆ›å»ºç‰¹å®šæ ¼å¼çš„æ•°æ®ï¼ˆ28bytesï¼‰å‘é€åˆ°Find My Networkï¼Œå¹¶ä¸”å°†å¥¹è§†ä½œå…¬é’¥ã€‚

| octet    | size   | description |
| -------- | ------ | ----------- |
| [0, 4)   | 4bytes | bit index   |
| [4, 8)   | 4bytes | message ID  |
| [8, 12)  | 4bytes | modem ID    |
| [12, 23) | 7bytes | Padding 0s  |
| 23       | 1byte  | bit value   |



To send a full message, the program simply loops over its bits and sends out one advertisement per bit with the public key that encodes its index and value.

åº”è¯¥å¦‚ä½•å‘é€å®Œæ•´çš„æ¶ˆæ¯å‘¢ï¼Œç¨‹å¼é€šè¿‡ç®€å•è½®è¯¢æ¶ˆæ¯çš„bitsï¼Œå¹¶ä¸”é’ˆå¯¹æ¯ä¸ªbitéƒ½å‘å‡ºä¸€æ¡BLEå¹¿æ’­ï¼Œå¹¶ä¸”ç”¨å…¬é’¥åŠ å¯†æ¶ˆæ¯çš„åºåˆ—å·è·Ÿå€¼ã€‚

<img src="send_my_3_encoding.png">



When fetching data, the receiving application will generate the same 28-byte arrays (two per bit, for the possible bit values 0 and 1) and query the Apple service with the SHA256 hashes of those "public keys". Only one of the two key ids should have location reports attached, which can then be interpreted (e.g. bit at index 0 equals 1).

æ‹‰å–æ•°æ®æ—¶ï¼Œæ¥æ”¶ç«¯ä¼šç”ŸæˆåŒæ ·å¤§å°çš„28byteæ•°ç»„ï¼Œç„¶åä¼ å…¥SHA256å‘Apple Serveræ¥queryæ•°æ®ã€‚ä¸¤ä¸ªKeyä¸­åªæœ‰ä¸€ä¸ªèƒ½å¤ŸåŒ¹é…åˆ°ä½ç½®æŠ¥å‘Šï¼Œç„¶åä½ç½®æŠ¥å‘Šå¯è¢«è§£å¯†ä¸è§£æã€‚

<img src="send_my_4_retrieving.png">



Note: Instead of only transferring one bit per message, we could also e.g. send a full byte by setting the last 8 bit of the public key. While this increases the sending bandwidth, on the receiving side, we now need to request 255 different key ids to fetch/"brute force" one byte (compared to 16 key IDs when it's encoded bit-by-bit).

å¦‚æœç”¨8bitsæ¥å˜åŒ–ä½œä¸ºå…¬é’¥çš„è¯ï¼Œæ¥æ”¶ç«¯åˆ™ä¼šç”Ÿæˆ255ç§ä¸åŒçš„Keyå»query Apple Serverï¼Œé™¤äº†å¢åŠ å¸¦å®½å¤–ï¼ŒOwner Deviceè¿˜éœ€è¦æ ¹æ®255ç§ç§˜é’¥è¿›è¡Œæš´åŠ›è§£å¯†ã€‚

## Implementation



### Sending side

â€œä¸¢å¤±è®¾å¤‡â€ç«¯

For the sending side I chose the ESP32, as it is a very common and low-cost microcontroller (and in a quick test it could change its BT MAC address much more quickly than e.g. a Linux-based Raspberry Pi). On boot, the OpenHaystack-based firmware broadcasts a hardcoded default message and then listens on the serial interface for any new data to broadcast in a loop until a new message is received. Broadcasting the public key actually means splitting it up and encoding the first 6 bytes in the Bluetooth MAC address (except for the first two bits as the Bluetooth standard requires them to be set to 1). You can check [Section 6.2 in the TU Darmstadt paper](https://arxiv.org/pdf/2103.02282.pdf) for more details on this hacky encoding.

ä½¿ç”¨ESP32ä½œä¸ºâ€œä¸¢å¤±è®¾å¤‡â€ã€‚å¯åŠ¨æ—¶ï¼ŒOpenHaystackä¼šç›‘å¬ä¸²å£çš„æ¶ˆæ¯ï¼ŒåŒæ—¶è¿›è¡Œé»˜è®¤æ¶ˆæ¯çš„å¾ªç¯BLEå¹¿æ’­ï¼Œç›´åˆ°æ”¶åˆ°æ–°çš„ä¸²å£æ¶ˆæ¯ã€‚å¹¿æ’­å…¬é’¥å®é™…ä¸Šæ„å‘³ç€æ‹†åˆ†å¥¹ä¸”ç¼–ç å‰6byteså¤§å°çš„è“ç‰™MACåœ°å€ã€‚ï¼ˆæ²¡çœ‹æ‡‚è¿™å¥æ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿï¼‰

I added a static prefix to my payload to not run into issues with the BT specification, and also included the incrementing bit index in the first 6 bytes of the public key, resulting in a different BT MAC address used for each transmitted bit, just in case there is some MAC address based rate limiting somewhere in the stack.

æˆ‘ä¼šä¸ºæ¶ˆæ¯æ·»åŠ ç‰¹æ®Šçš„å‰ç¼€é¿å…é‡åˆ°è“ç‰™è§„èŒƒé—®é¢˜ï¼ŒåŒæ—¶ä¹ŸåŒ…å«é€’å¢çš„åºåˆ—å·åœ¨å…¬é’¥çš„å‰6ä¸ªbytesä¸­ã€‚å¯¼è‡´æ¯ä¸ªtransmitted bitä½¿ç”¨ä¸åŒçš„è“ç‰™MACåœ°å€ï¼Œé‚£ä¹ˆæ¶ˆæ¯ä¼ è¾“é€Ÿç‡çš„é™åˆ¶å°±åœ¨äºMACåœ°å€çš„å˜åŒ–é€Ÿåº¦ã€‚ï¼ˆESP32æ¯”æ ‘è“æ´¾çš„è“ç‰™MACåœ°å€åˆ‡æ¢å¾—å¿«ï¼Œæ˜¯ESP32çš„ä¼˜åŠ¿ã€‚ä½†æ˜¯ï¼Œå¥½å¥‡æ€ªçš„æ•°æ®ä¼ è¾“è®¾è®¡ï¼Œä¸çŸ¥æ‰€äº‘ï¼‰

### Retrieval side

â€œæ¥æ”¶â€ç«¯ï¼ŒOwner Device

The Mac application is also based on OpenHaystack and uses the same AppleMail plugin trick to send properly authenticated location retrieval requests to the Apple backend. The user is prompted for the 4 byte modem ID (can be set when flashing the ESP firmware), after which the application will automatically fetch, decode and display the message with id 0. Afterwards the user can fetch other messages or change the modem.

MacOS applicationä¹Ÿæ˜¯åŸºäºOpenHaystackçš„ç¨‹å¼ï¼Œåˆ©ç”¨AppleMail pluginæ¬ºéª—Apple Serverï¼Œå‘é€åˆæ³•çš„ä½ç½®æŠ¥å‘Šçš„è¯·æ±‚ã€‚

A message is fetched 16 bytes (128 bit) at a time (by querying 256 key ids) until no reports can be found (for a full byte).



### Small complication: public key validity

æœ‰æ•ˆå…¬é’¥çš„è®¡ç®—ï¼ˆæœ€ç¡¬æ ¸éƒ¨åˆ†ï¼‰

Having implemented both the sending and receiving side, I performed a first test by broadcasting and trying to receive a 32 bit value. After a few minutes, I could retrieve 23 out of the 32 bits, each one being unambiguous and with ~100 location reports, but no reports for the remaining 9 bits.

å‘é€ç«¯ä¸æ¥æ”¶ç«¯éƒ½å·²ç»å®ç°åï¼Œæˆ‘æ‰§è¡Œç¬¬ä¸€æ¬¡æµ‹è¯•ï¼Œå¹¿æ’­32bitï¼ˆ4bytesï¼‰çš„å†…å®¹ï¼Œå¹¶å‘Apple Serverè¯·æ±‚ã€‚å‡ åˆ†é’Ÿåï¼Œæˆ‘è·å–åˆ°32bitsä¸­çš„23ä¸ªbitï¼Œä¸”æ¯ä¸ªæ¶ˆæ¯éƒ½æ˜¯æ­£ç¡®çš„ï¼Œå¤§çº¦æœ‰100å¤šä»½ä½ç½®æŠ¥å‘Šï¼Œä½†æ²¡æœ‰ä¸€ä»½æŠ¥å‘Šæœ‰å…³äºå‰©ä½™9bitsçš„æ¶ˆæ¯ã€‚

I suspected that some of the generated public keys were rejected by the nearby Apple Devices during the ECIES encryption as invalid public keys, and could quickly confirm this by trying to import each of the generated payloads as SEC1-encoded public keys on the P224 curve using Python's fastecdsa: For every bit that I could not find location reports for, the microcontroller had broadcasted a public key, which throws an InvalidSEC1PublicKey exception during the fastecdsa key import.

æˆ‘æ€€ç–‘ç”Ÿæˆçš„å…¬é’¥ä¸­æœ‰ä¸€äº›æ˜¯æ— æ•ˆçš„ï¼Œåœ¨Finding Deviceæ‰§è¡ŒECIESåŠ å¯†æ—¶ä¼šå‘ç”Ÿé”™è¯¯ã€‚æˆ‘ç”¨Pythonâ€˜s fastecdsaåŒ…å–å¾—äº†å¿«é€ŸéªŒè¯ã€‚

Some background info on the crypto involved:

å¯†ç æŠ€æœ¯æ¶‰åŠå¦‚ä¸‹ä¸€äº›èƒŒæ™¯çŸ¥è¯†

- The 28-byte EC public represents the SEC1-encoded X coordinate of a point

28byteå¤§å°çš„ECå…¬é’¥è¡¨ç¤ºSEC1ç¼–ç åæ ‡ç³»ä¸­ä¸€ä¸ªç‚¹çš„Xåæ ‡ã€‚ï¼ˆæ²¡çœ‹æ‡‚ä»€ä¹ˆæ„æ€ï¼‰

- A SEC1 public key usually also has a "sign" bit that defines which of the two possible Y coordinates for a specific X coordinate should be encoded. This bit is not broadcasted and irrelevant for the public key's validity

SEC1 å…¬é’¥é€šå¸¸è¿˜æœ‰ä¸€ä¸ªâ€œç¬¦å·â€ä½ï¼Œç”¨äºå®šä¹‰åº”ç¼–ç ç‰¹å®š X åæ ‡çš„ä¸¤ä¸ªå¯èƒ½ Y åæ ‡ä¸­çš„å“ªä¸€ä¸ªã€‚ è¯¥ä½ä¸å¹¿æ’­ï¼Œä¸å…¬é’¥çš„æœ‰æ•ˆæ€§æ— å…³ã€‚

- During the decoding of a compressed public key, the corresponding Y coordinate is calculated using the fixed curve parameters and tested for validity. This is the test that fails for some of the generated public keys. You can check Section 3.2.2 of "[Validation of Elliptic Curve Public Keys](https://iacr.org/archive/pkc2003/25670211/25670211.pdf)" for more details:

åœ¨å‹ç¼©å…¬é’¥çš„è§£ç è¿‡ç¨‹ä¸­ï¼Œä½¿ç”¨å›ºå®šæ›²çº¿å‚æ•°è®¡ç®—ç›¸åº”çš„ Y åæ ‡å¹¶æµ‹è¯•å…¶æœ‰æ•ˆæ€§ã€‚ è¿™æ˜¯æŸäº›ç”Ÿæˆçš„å…¬é’¥å¤±è´¥çš„æµ‹è¯•ã€‚

<img src="send_my_5_ecc_validity.png">



There are at least two ways to solve this problem of invalid public keys:

1. Before broadcasting a payload, check whether the EC point it represents is actually valid for the used curve. If not, increment a counter until a valid public key is found. This process is deterministic and can similarly be performed offline by the retrieval application before querying a key id

åœ¨å¹¿æ’­æœ‰æ•ˆè½½è·ä¹‹å‰ï¼Œè¯·æ£€æŸ¥å®ƒæ‰€ä»£è¡¨çš„ EC ç‚¹å¯¹äºæ‰€ä½¿ç”¨çš„æ›²çº¿æ˜¯å¦ç¡®å®æœ‰æ•ˆã€‚ å¦‚æœæ²¡æœ‰ï¼Œå¢åŠ ä¸€ä¸ªè®¡æ•°å™¨ç›´åˆ°æ‰¾åˆ°ä¸€ä¸ªæœ‰æ•ˆçš„å…¬é’¥ã€‚ æ­¤è¿‡ç¨‹æ˜¯ç¡®å®šæ€§çš„ï¼Œå¹¶ä¸”å¯ä»¥ç±»ä¼¼åœ°ç”±æ£€ç´¢åº”ç”¨ç¨‹åºåœ¨æŸ¥è¯¢å¯†é’¥ ID ä¹‹å‰ç¦»çº¿æ‰§è¡Œã€‚

2. Interpret the payload as private key (instead of public key). While a compressed 28 byte public key is interpreted as the X coordinate of a potential point on the curve, a 28 byte private key is interpreted as the scalar in a [EC point/scalar multiplication](https://en.wikipedia.org/wiki/Elliptic_curve_point_multiplication), thus always resulting in a valid point on the curve (the public key)

å°†æœ‰æ•ˆè´Ÿè½½è§£é‡Šä¸ºç§é’¥ï¼ˆè€Œä¸æ˜¯å…¬é’¥ï¼‰ã€‚ å‹ç¼©çš„ 28 å­—èŠ‚å…¬é’¥è¢«è§£é‡Šä¸ºæ›²çº¿ä¸Šæ½œåœ¨ç‚¹çš„ X åæ ‡ï¼Œè€Œ 28 å­—èŠ‚ç§é’¥è¢«è§£é‡Šä¸º [EC ç‚¹/æ ‡é‡ä¹˜æ³•](https://en.wikipedia.org) ä¸­çš„æ ‡é‡ /wiki/Elliptic_curve_point_multiplicationï¼‰ï¼Œå› æ­¤æ€»æ˜¯åœ¨æ›²çº¿ä¸Šäº§ç”Ÿä¸€ä¸ªæœ‰æ•ˆç‚¹ï¼ˆå…¬é’¥ï¼‰

The second option has the advantage that for each received bit, we'd also be able to decrypt the location reports to find out the location it was received at, but it requires a bit more processing. While implementing this option, I found that due to [bugs in the EC multiplication implementation](https://github.com/kmackay/micro-ecc/issues/128) of the used uECC library, for some private keys the ESP would calculate different public keys than both BoringSSL on Mac and Python's fastecdsa (accidential differential fuzzing?). Those public keys were even treated as invalid by uECC's own uECC_valid_public_key() function. I therefore chose to go with option 1 for this PoC.

ç¬¬äºŒä¸ªé€‰é¡¹çš„ä¼˜ç‚¹æ˜¯ï¼Œå¯¹äºæ¯ä¸ªæ¥æ”¶åˆ°çš„ä½ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥è§£å¯†ä½ç½®æŠ¥å‘Šä»¥æ‰¾å‡ºæ¥æ”¶å®ƒçš„ä½ç½®ï¼Œä½†å®ƒéœ€è¦æ›´å¤šçš„å¤„ç†ã€‚ä½†uECCåº“æœ‰bugå¯¼è‡´ç”Ÿæˆçš„å…¬é’¥ä¸åˆæ³•ï¼Œæ‰€ä»¥æœ€ç»ˆé‡‡ç”¨ç¬¬ä¸€ä¸ªé€‰é¡¹ã€‚

<img src="send_my_6_sending.png">



## Testing / Performance



With the public key validity check implemented, everything worked flawlessly. While I didn't do extensive performance testing and measurements, here are some estimates:

è™½ç„¶æˆ‘æ²¡æœ‰è¿›è¡Œå¤§é‡çš„æ€§èƒ½æµ‹è¯•å’Œæµ‹é‡ï¼Œä½†è¿™é‡Œæœ‰ä¸€äº›ä¼°è®¡ï¼š

- The **sending rate** on the microcontroller is currently **~3 bytes/second**. Higher speeds could be achieved e.g. simply by caching the encoding results or by encoding one byte per advertisement

å¾®æ§åˆ¶å™¨ä¸Šçš„**å‘é€é€Ÿç‡**ç›®å‰ä¸º **~3 å­—èŠ‚/ç§’**ã€‚å¯ä»¥å®ç°æ›´é«˜çš„é€Ÿåº¦ï¼Œä¾‹å¦‚åªéœ€ç¼“å­˜ç¼–ç ç»“æœæˆ–å¯¹æ¯ä¸ªå¹¿æ’­ç¼–ç ä¸€ä¸ªå­—èŠ‚ã€‚

- In my tests, the **receiving rate** was limited by slow Mac hardware. Retrieving **16 bytes** within one request takes **~5 seconds**

åœ¨æˆ‘çš„æµ‹è¯•ä¸­ï¼Œ**æ¥æ”¶ç‡**å—åˆ°æ…¢é€Ÿ Mac ç¡¬ä»¶çš„é™åˆ¶ã€‚ åœ¨ä¸€ä¸ªè¯·æ±‚ä¸­æ£€ç´¢ **16 å­—èŠ‚** éœ€è¦ **~5 ç§’**ã€‚

- The **latency** is usually **between 1 and 60 minutes** depending on how many devices are around and other random factors. The following graphic shows the delay distribution between a public key broadcast and the corresponding location report being uploaded. Please note however, that this is per location report upload and does not directly represent the time until broadcasted data can be downloaded (already the first location report from any nearby Apple devices suffices for this)

**å»¶è¿Ÿ**é€šå¸¸**ä»‹äº 1 åˆ° 60 åˆ†é’Ÿ** ä¹‹é—´ï¼Œå…·ä½“å–å†³äºå‘¨å›´çš„è®¾å¤‡æ•°é‡å’Œå…¶ä»–éšæœºå› ç´ ã€‚



<img src="send_my_7_report_delays.png">





## Potential use cases



While I was mostly just curious about whether it would be possible, I would imagine the most common use case to be **uploading sensor readings or any data** from **IoT devices** without a broadband modem, SIM card, data plan or Wifi connectivity. With Amazon [running a similar network called *Sidewalk* that uses Echo devices](https://www.amazon.com/Amazon-Sidewalk/b?ie=UTF8&node=21328123011) there might very well be demand for it. Since the Finding devices cache received broadcasts until they have an Internet connection, the sensors can even send out data from areas without mobile coverage as long as people pass the area.



In the world of **high-security networks**, where combining lasers and scanners seems to be a [noteworthy technique](https://www.schneier.com/blog/archives/2017/04/jumping_airgaps.html) to bridge the airgap, the visitor's Apple devices might also become feasible intermediaries to **exfiltrate data from** certain **airgapped systems** or Faraday caged rooms.



It also seems like the Offline Finding protocol could be used to **deplete nearby iPhone's mobile data plans**. With the number of location reports from a Finder device being limited (to 255 reports/submission due to a 1 byte count value) and each report being over 100 byte, broadcasting many unique public keys should result in an amplified amount of mobile traffic sent by the phone. While I haven't noticed any rate limiting on the number of location reports sent out, I also haven't tested how much data this would consume.



## Mitigation

å‡è½»æ»¥ç”¨çš„æƒ…å†µ

As mentioned initially, it would be hard for Apple to defend against this kind of misuse in case they wanted to.

æ­£å¦‚æœ€åˆæåˆ°çš„é‚£æ ·ï¼Œå¦‚æœ Apple æ„¿æ„çš„è¯ï¼Œå¾ˆéš¾é˜²èŒƒè¿™ç§æ»¥ç”¨ã€‚

Apple designed the system on the principle of data economy. They cannot read unencrypted locations and do not know which public keys belong to your AirTag, or even which public key a certain encrypted location report belongs to (as they only receive the public key's SHA256 hash).

è‹¹æœæ ¹æ®æ•°æ®ç»æµçš„åŸåˆ™è®¾è®¡äº†è¯¥ç³»ç»Ÿã€‚ ä»–ä»¬æ— æ³•è¯»å–æœªåŠ å¯†çš„ä½ç½®ï¼Œä¹Ÿä¸çŸ¥é“å“ªäº›å…¬é’¥å±äºæ‚¨çš„ AirTagï¼Œç”šè‡³ä¸çŸ¥é“æŸä¸ªåŠ å¯†ä½ç½®æŠ¥å‘Šå±äºå“ªä¸ªå…¬é’¥ï¼ˆå› ä¸ºä»–ä»¬åªæ¥æ”¶å…¬é’¥çš„ SHA256 å“ˆå¸Œå€¼ï¼‰ã€‚

In this light, the stated restriction of 16 AirTags per Apple ID seems interesting, as to me it does not seem that Apple can currently enforce this.

æœ‰é‰´äºæ­¤ï¼Œå£°æ˜çš„æ¯ä¸ª Apple ID 16 ä¸ª AirTag çš„é™åˆ¶ä¼¼ä¹å¾ˆæœ‰è¶£ï¼Œåœ¨æˆ‘çœ‹æ¥ï¼ŒApple ç›®å‰ä¼¼ä¹æ— æ³•å¼ºåˆ¶æ‰§è¡Œæ­¤æ“ä½œã€‚

However, further hardening of the system might e.g. be possible in the following two areas:

ç„¶è€Œï¼Œç³»ç»Ÿçš„è¿›ä¸€æ­¥å¼ºåŒ–å¯èƒ½ä¾‹å¦‚ å¯ä»¥åœ¨ä»¥ä¸‹ä¸¤ä¸ªæ–¹é¢è¿›è¡Œï¼š

- **Authentication of the BLE advertisement.** Currently, Finder devices can not differentiate between e.g. an AirTag and a clone based on OpenHaystack, thus allowing the spoofing of many thousand non-existing AirTags to encode and transmit data. Usually one would consider signing the public keys, however with the BLE advertisement size already completely used up, AirTags being low power and not connected to the internet, and the broadcasted keys constantly rotating, this presents quite a challenge.

**BLE å¹¿æ’­çš„è®¤è¯ã€‚** ç›®å‰ï¼ŒFinder è®¾å¤‡æ— æ³•åŒºåˆ†ä¾‹å¦‚ ä¸€ä¸ª AirTag å’Œä¸€ä¸ªåŸºäº OpenHaystack çš„å…‹éš†ï¼Œä»è€Œå…è®¸æ¬ºéª—æ•°åƒä¸ªä¸å­˜åœ¨çš„ AirTag æ¥ç¼–ç å’Œä¼ è¾“æ•°æ®ã€‚ é€šå¸¸ä¼šè€ƒè™‘å¯¹å…¬é’¥è¿›è¡Œç­¾åï¼Œä½†æ˜¯ç”±äº BLE å¹¿æ’­å¤§å°å·²ç»å®Œå…¨ç”¨å®Œï¼ŒAirTags ä½åŠŸè€—ä¸”æœªè¿æ¥åˆ°äº’è”ç½‘ï¼Œå¹¶ä¸”å¹¿æ’­çš„å¯†é’¥ä¸æ–­è½®æ¢ï¼Œè¿™æå‡ºäº†ç›¸å½“å¤§çš„æŒ‘æˆ˜ã€‚

- **Rate limiting of the location report retrieval.** While Apple does not know whether the requested key id belongs to one of the requesting user's AirTag, they could cache the requested key ids and ensure that only 16 new key ids are queried per 15 minutes and Apple ID (after allowing a much higher number for an initial search during the last days). While easier to implement, this mitigation can be bypassed by cycling through multiple free Apple IDs for data retrieval.

**ä½ç½®æŠ¥å‘Šæ£€ç´¢çš„é€Ÿç‡é™åˆ¶ã€‚** è™½ç„¶ Apple ä¸çŸ¥é“è¯·æ±‚çš„å¯†é’¥ ID æ˜¯å¦å±äºè¯·æ±‚ç”¨æˆ·çš„ AirTag ä¹‹ä¸€ï¼Œä½†ä»–ä»¬å¯ä»¥ç¼“å­˜è¯·æ±‚çš„å¯†é’¥ ID å¹¶ç¡®ä¿æ¯ 15 ä¸ªä»…æŸ¥è¯¢ 16 ä¸ªæ–°çš„å¯†é’¥ ID åˆ†é’Ÿå’Œ Apple IDï¼ˆåœ¨æœ€åå‡ å¤©å…è®¸æ›´é«˜çš„åˆå§‹æœç´¢æ•°å­—ä¹‹åï¼‰ã€‚ è™½ç„¶æ›´å®¹æ˜“å®ç°ï¼Œä½†å¯ä»¥é€šè¿‡å¾ªç¯ä½¿ç”¨å¤šä¸ªå…è´¹ Apple ID è¿›è¡Œæ•°æ®æ£€ç´¢æ¥ç»•è¿‡è¿™ç§ç¼“è§£æªæ–½ã€‚

## Conclusion



In this blog post, we have answered the initial question, whether it's possible to upload arbitrary data using other people's Apple devices, with a clear yes.

åœ¨è¿™ç¯‡åšæ–‡ä¸­ï¼Œæˆ‘ä»¬å·²ç»å›ç­”äº†æœ€åˆçš„é—®é¢˜ï¼Œå³æ˜¯å¦å¯ä»¥ä½¿ç”¨å…¶ä»–äººçš„ Apple è®¾å¤‡ä¸Šä¼ ä»»æ„æ•°æ®ï¼Œç­”æ¡ˆæ˜¯è‚¯å®šçš„ã€‚

An ESP32 modem firmware and macOS data retrieval application was implemented and is [available on Github](https://github.com/positive-security/send-my) for others to experiment with.



Please note that this is a PoC implementation and the "protocol" itself is neither encrypted nor authenticated. Exemplary, you can explore the data of modem ID 0x42424242 by simply entering its ID (maybe in the meantime somebody has also demonstrated the protocol's lack of authentication ğŸ˜‰).

è¯·æ³¨æ„ï¼Œè¿™æ˜¯ä¸€ä¸ª PoC å®ç°ï¼Œâ€œåè®®â€æœ¬èº«æ—¢æœªåŠ å¯†ä¹Ÿæœªç»è¿‡èº«ä»½éªŒè¯ã€‚ ä¾‹å¦‚ï¼Œæ‚¨å¯ä»¥é€šè¿‡ç®€å•åœ°è¾“å…¥è°ƒåˆ¶è§£è°ƒå™¨ ID æ¥æ¢ç´¢è°ƒåˆ¶è§£è°ƒå™¨ ID 0x42424242 çš„æ•°æ®ï¼ˆä¹Ÿè®¸åŒæ—¶æœ‰äººä¹Ÿè¯æ˜äº†è¯¥åè®®ç¼ºä¹èº«ä»½éªŒè¯ğŸ˜‰ï¼‰ã€‚

Final note: While writing this blog post, I noticed a "status" byte that is included in the BLE advertisement and apparently used e.g. as battery level indicator. In combination with deterministically generated rotating private keys, this is probably another way to leak data with one byte per advertisement, but I haven't tested this approach.

æœ€åä¸€ç‚¹ï¼šåœ¨å†™è¿™ç¯‡åšæ–‡æ—¶ï¼Œæˆ‘æ³¨æ„åˆ° BLE å¹¿æ’­ä¸­åŒ…å«ä¸€ä¸ªâ€œçŠ¶æ€â€å­—èŠ‚ï¼Œæ˜¾ç„¶ä½¿ç”¨äº†ä¾‹å¦‚ ä½œä¸ºç”µæ± ç”µé‡æŒ‡ç¤ºå™¨ã€‚ ç»“åˆç¡®å®šæ€§ç”Ÿæˆçš„æ—‹è½¬ç§é’¥ï¼Œè¿™å¯èƒ½æ˜¯å¦ä¸€ç§ä»¥æ¯ä¸ªå¹¿å‘Šä¸€ä¸ªå­—èŠ‚æ³„æ¼æ•°æ®çš„æ–¹æ³•ï¼Œä½†æˆ‘è¿˜æ²¡æœ‰æµ‹è¯•è¿‡è¿™ç§æ–¹æ³•ã€‚





# Who Can Find My Devices

**Security and Privacy of Appleâ€™s Crowd-Sourced Bluetooth Location Tracking System**



## Abstract

Overnight, Apple has turned its hundreds-of- million-device ecosystem into the worldâ€™s largest crowd- sourced location tracking network called offline finding (OF). OF leverages online finder devices to detect the presence of missing offline devices using Bluetooth and report an approximate location back to the owner via the Internet. While OF is not the first system of its kind, it is the first to commit to strong privacy goals. In particular, OF aims to ensure finder anonymity, un- trackability of owner devices, and confidentiality of location reports. This paper presents the first comprehensive security and privacy analysis of OF. To this end, we recover the specifications of the closed-source OF protocols by means of reverse engineering. We experimentally show that unauthorized access to the location reports allows for accurate device tracking and retrieving a userâ€™s top locations with an error in the order of 10 meters in urban areas. While we find that OFâ€™s design achieves its privacy goals, we discover two distinct design and implementation flaws that can lead to a location correlation attack and unauthorized access to the location history of the past seven days, which could deanonymize users. Apple has partially addressed the issues following our responsible disclosure. Finally, we make our research artifacts publicly available.

ä¸€å¤œä¹‹é—´ï¼ŒAppleå°†å…¶æ•°ä»¥äº¿è®¡çš„è®¾å¤‡ç”Ÿæ€ç³»ç»Ÿå˜æˆäº†ä¸–ç•Œä¸Šæœ€å¤§çš„Crowd-sourcedä½ç½®è·Ÿè¸ªç½‘ç»œï¼Œå«åšoffline findingï¼ˆOFï¼‰ã€‚OFåˆ©ç”¨online finder devicesçš„è“ç‰™å»æ¢æµ‹missing offline devicesçš„å­˜åœ¨ï¼Œå¹¶é€šè¿‡Internetå°†å¤§è‡´ä½ç½®æŠ¥å‘Šç»™ownerã€‚è™½ç„¶OFä¸æ˜¯ç¬¬ä¸€ä¸ªè¿™ç§ç±»å‹çš„ç³»ç»Ÿï¼Œä½†å¥¹å´æ˜¯ç¬¬ä¸€ä»¥å®ç°å¼ºéšç§ä¸ºç›®æ ‡çš„è¿™ç±»ç³»ç»Ÿã€‚ç‰¹åˆ«çš„ï¼ŒOFæ—¨åœ¨ç¡®ä¿finderçš„åŒ¿åæ€§ï¼Œowner devicesçš„ä¸å¯è¿½è¸ªæ€§ï¼Œä½ç½®æŠ¥å‘Šçš„æœºå¯†æ€§ã€‚æœ¬è®ºæ–‡å¯¹OFåšä¸€æ¬¡å…¨é¢çš„å®‰å…¨å’Œéšç§åˆ†æã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬é€šè¿‡é€†å‘å·¥ç¨‹æŠ€æœ¯æ¢å¤äº†é—­æºåè®®OFçš„specã€‚We experimentally show that unauthorized access to the location reports allows for accurate device tracking and retrieving a userâ€™s top locations with an error in the order of 10 meters in urban areas. è™½ç„¶æˆ‘ä»¬è¯æ˜äº†OFçš„è®¾è®¡å®ç°äº†å¥¹çš„éšç§ç›®æ ‡ï¼Œä½†æ˜¯æˆ‘ä»¬ä¹Ÿå‘ç°äº†ä¸¤ç‚¹ä¸åŒçš„è®¾è®¡å’Œå®ç°ä¸Šçš„flawsï¼Œå¥¹ä»¬å¯èƒ½é€ æˆä½ç½®å…³è”æ”»å‡»å’Œè¿‡å»7å¤©çš„ä½ç½®æŠ¥å‘Šçš„æœªæˆæƒè®¿é—®ï¼Œå¯èƒ½é€ æˆå»åŒ¿ååŒ–ã€‚ç´§è·Ÿæˆ‘ä»¬è´Ÿè´£äººçš„æ›å…‰ï¼ŒAppleå·²ç»ä¿®å¤äº†å…¶ä¸­ä¸€äº›issueã€‚æœ€åï¼Œæˆ‘ä»¬å…¬å¼€æˆ‘ä»¬çš„research artifacesã€‚



## Introduction

In 2019, Apple introduced *offline finding (OF)*, a proprietary crowd-sourced location tracking system for offline devices. The basic idea behind OF is that so-called *finder* devices can detect the presence of other *lost* offline devices using Bluetooth Low Energy (BLE) and use their Internet connection to report an approximate location back to the *owner*. Appleâ€™s OF network consists of â€œhundreds of millionsâ€ of devices [4], making it the currently largest crowd-sourced location tracking system in existence. We expect the network to grow as OF will officially support the tracking of non-Apple devices in the future [6]. Regardless of its size, the system has sparked considerable interest and discussion within the broader tech and security communities [28, 29] as Apple makes strong security and privacy claims supported by new cryptographic primitives that other commercial systems are lacking [51]. In particular, Apple claims that it cannot access location reports, finder identities are not revealed, and BLE advertisements cannot be used to track devices [35]. Apple has yet to provide ample proof for their claims as, until today, only selected components have been publicized [4, 6, 35].

æ—©åœ¨2019å¹´ï¼ŒAppleä»‹ç»äº†ç§æœ‰çš„offline findingï¼ˆOFï¼‰ï¼Œä¸€æ¬¾é’ˆå¯¹offline devicesçš„è‡ªç ”çš„crowd-sourcedä½ç½®è¿½è¸ªç³»ç»Ÿã€‚OFèƒŒåçš„åŸºæœ¬æ€æƒ³ï¼šfinder devicesåˆ©ç”¨BLEæŠ€æœ¯æ¢æµ‹å…¶ä»–äººlost offline devicesï¼Œå¹¶ä½¿ç”¨è‡ªå·±çš„Internetè¿æ¥ä¸ŠæŠ¥ç²—ç•¥ä½ç½®çš„æŠ¥å‘Šç»™ownerã€‚Appleçš„OF networkç”±ä¸Šäº¿çš„è®¾å¤‡ç»„æˆï¼Œä¹Ÿæ˜¯ç›®å‰æœ€å¤§çš„crowd-sourcedä½ç½®è¿½è¸ªç³»ç»Ÿã€‚æˆ‘ä»¬é¢„æœŸç½‘ç»œå°†è¿›ä¸€æ­¥å£®å¤§ï¼Œå› ä¸ºOFæœªæ¥å°†å®˜æ–¹æ”¯æŒnon-Apple devicesã€‚æ— è®ºå…¶è§„æ¨¡å¦‚ä½•ï¼ŒOFç³»ç»Ÿå·²ç»åœ¨broaderæŠ€æœ¯å’Œå®‰å…¨ç¤¾åŒºä¸­sparked considerableå…´è¶£å’Œè®¨è®ºï¼Œå› ä¸ºAppleä½œå‡ºäº†å¼ºå®‰å…¨å’Œéšç§å£°æ˜ï¼ˆç”±æ–°çš„cryptographic primitivesæ”¯æŒï¼Œè¿™æ˜¯å…¶ä»–å•†ä¸šç³»ç»Ÿæ‰€ç¼ºå°‘çš„ï¼‰ã€‚ç‰¹åˆ«çš„ï¼ŒAppleè¡¨ç¤ºå¥¹è‡ªå·±æ— æ³•è®¿é—®ä½ç½®æŠ¥å‘Šï¼Œfinder devicesçš„èº«ä»½ä¹Ÿæ— æ³•è¢«é€éœ²ï¼Œä¸”BLEå¹¿æ’­ä¹Ÿæ— æ³•è¢«ç”¨æ¥è¿½è¸ªã€‚å½“ç„¶ï¼ŒAppleè¿˜æ²¡ä¸ºå¥¹çš„å£°æ˜æä¾›ampleè¯æ®ï¼Œåªæœ‰é€‰æ‹©æ€§åœ°å…¬å¼€å…¶ä¸­çš„ç»„ä»¶ã€‚



### Contribution

æ„ä¹‰ä¸ä»·å€¼

This paper challenges Appleâ€™s security and privacy claims and examines the system design and implementation for vulnerabilities. To this end, we first analyze the involved OF system components on macOS and iOS using reverse engineering and present the proprietary protocols involved during *losing*, *searching*, and *finding* devices. In short, devices of one owner agree on a set of so-called rolling publicâ€“private key pairs. Devices without an Internet connection, i.e., without cellular or Wi-Fi connectivity, emit BLE advertisements that encode one of the rolling public keys. Finder devices overhearing the advertisements encrypt their current location under the rolling public key and send the location report to a central Apple-run server. When searching for a lost device, another owner device queries the central server for location reports with a set of known rolling public keys of the lost device. The owner can decrypt the reports using the corresponding private key and retrieve the location.

è®ºæ–‡æŒ‘æˆ˜Appleçš„å®‰å…¨éšç§å£°æ˜ï¼Œä¸”è¯•éªŒOFç³»ç»Ÿè®¾è®¡ä¸å®ç°çš„æ¼æ´ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬é¦–å…ˆå¯¹macOSå’ŒiOSä¸­OFç›¸å…³æ¨¡å—è¿›è¡Œé€†å‘åˆ†æï¼Œå±•ç¤ºåœ¨lostingï¼Œsearchingå’Œfindingä¸‰ä¸ªåœºæ™¯ä¸­çš„Appleè‡ªç ”åè®®ã€‚ç®€è€Œè¨€ä¹‹ï¼Œownerä¸å…¶æ‹¥æœ‰çš„devicesä¼šåå•†å‡ºä¸€ç»„rolling public-private å¯†é’¥å¯¹ã€‚æ²¡æœ‰Internetè¿æ¥çš„Devicesï¼Œè­¬å¦‚ç¼ºå°‘èœ‚çªç½‘ç»œä¸Wifiç½‘ç»œçš„è®¾å¤‡ï¼Œä¼šå‘å°„æºå¸¦rolling publicå¯†é’¥çš„BLEå¹¿æ’­ã€‚ç›‘å¬BLEå¹¿æ’­çš„Finder devicesåˆ©ç”¨rolling public keyåŠ å¯†è‡ªèº«çš„ä½ç½®ä¿¡æ¯ä¸Šä¼ åˆ°Apple Serverã€‚Search lost devicesæ—¶ï¼Œæƒ³è¦ä½ç½®æŠ¥å‘Šçš„owner deviceå‘Apple Serverå‘é€æºå¸¦ä¸€ç»„rolling public keyçš„è¯·æ±‚ã€‚åªæœ‰owner deviceèƒ½å¤Ÿè§£å¯†å’Œè§£æè¿™äº›ä½ç½®æŠ¥å‘Šï¼Œå› ä¸ºåªæœ‰å¥¹æœ‰å¯¹åº”çš„ç§é’¥ã€‚



Based on our analysis, we assess the security and privacy of the OF system. We find that the overall design achieves Appleâ€™s specific goals. However, we discovered two distinct design and implementation vulnerabilities that seem to be outside of Appleâ€™s threat model but can have severe consequences for the users. First, the OF design allows Apple to correlate different ownersâ€™ locations if their locations are reported by the same finder, effectively allowing Apple to construct a social graph. Second, malicious macOS applications can retrieve and decrypt the OF location reports of the last seven days for all its users and for *all* of their devices as cached rolling advertisement keys are stored on the file system in cleartext. We demonstrate that the latter vulnerability is exploitable and verify that the accuracy of the retrieved reportsâ€”in factâ€”allows the attacker to locate and identify their victim with high accuracy. We have shared our findings with Apple via responsible disclosure, who have meanwhile fixed one issue via an OS update (CVE-2020-9986, cf. *Responsible Disclosure* section for details). We summarize our key contributions.

åŸºäºæˆ‘ä»¬çš„åˆ†æï¼Œæˆ‘ä»¬è¯„ä¼°OF systemçš„å®‰å…¨æ€§å’Œéšç§æ€§ã€‚æˆ‘ä»¬è¯´OFç³»ç»Ÿçš„æ•´ä½“è®¾è®¡å®ç°äº†Appleç‰¹å®šçš„ç›®æ ‡ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬å‘ç°ä¸¤å¤„ä¸åŒçš„è®¾è®¡å®ç°æ¼æ´ï¼Œè¿™äº›æ¼æ´ä¼¼ä¹be outside of Appleçš„å¨èƒæ¨¡å‹ï¼Œä½†å¯¹ç”¨æˆ·ä¼šé€ æˆä¸¥é‡åæœã€‚

* ç¬¬ä¸€ï¼ŒOFçš„è®¾è®¡æ˜¯å…è®¸Appleå…³è”ä¸åŒownerçš„ä½ç½®çš„ï¼Œå¦‚æœä»–ä»¬è¢«åŒä¸€ä¸ªfinder deviceä¸ŠæŠ¥ä¿¡æ¯ï¼ŒAppleèƒ½é«˜æ•ˆåœ°æ„å»ºç¤¾äº¤å›¾è°±ã€‚
* ç¬¬äºŒï¼ŒmacOSçš„æ¶æ„ç¨‹åºèƒ½å¤Ÿæ£€ç´¢å’Œè§£å¯†ç”¨æˆ·7å¤©å†…çš„ä½ç½®æŠ¥å‘Šï¼Œå› ä¸ºrolling private-keyä¼šä»¥æ˜æ–‡çš„å½¢å¼ç¼“å­˜åœ¨æ–‡ä»¶ç³»ç»Ÿä¸­ã€‚

æˆ‘ä»¬demonstrateäº†åä¸€ä¸ªæ¼æ´æ˜¯å¯è¢«åˆ©ç”¨çš„ï¼Œä¹ŸéªŒè¯äº†è¢«ç´¢å¼•å‡ºçš„æŠ¥å‘Šçš„å‡†ç¡®æ€§ã€‚äº‹å®ä¸Šï¼Œè¿™å…è®¸äº†æ”»å‡»è€…å¯é«˜ç²¾å‡†åœ°è¿½è¸ªå’Œè¯†åˆ«å—å®³è€…ã€‚æˆ‘ä»¬å·²ç»å‘Appleåˆ†äº«äº†æˆ‘ä»¬çš„è°ƒæŸ¥ç»“æœï¼Œä¸æ­¤åŒæ—¶ï¼ŒAppleé€šè¿‡ç³»ç»Ÿå‡çº§å·²ç»ä¿®å¤äº†ä¸€ä¸ªissueã€‚æˆ‘ä»¬æ€»ç»“å…³é”®çš„contributionsã€‚

* We provide a comprehensive specification of the OF protocol components for losing, searching, and finding devices. Our PoC ï¼ˆProof of Conceptï¼‰implementation allows for tracking non-Apple devices via Appleâ€™s OF network.

  æä¾›äº†OFç³»ç»Ÿå…¨é¢çš„specï¼ŒåŒ…æ‹¬losingï¼Œsearchingå’Œfindingåœºæ™¯ã€‚ç†è®ºä¸Šè¯æ˜äº†æˆ‘ä»¬å¯ä»¥åˆ©ç”¨OFç³»ç»Ÿæ¥è¿½è¸ªnon-Appleè®¾å¤‡ã€‚

* We experimentally evaluate the accuracy of real-world location reports for different forms of mobility (by car, train, and on foot). We show that (1) a walking userâ€™s path can be tracked with a mean error of less than 30m in a metropolitan area and (2) the top locations of a user such as home and workplace can be inferred reliably and precisely (error in the order of 10 m) from a one-week location trace.

  æˆ‘ä»¬é€šè¿‡å®éªŒè¯„ä¼°å‡ºä¸åŒå½¢å¼çš„ç§»åŠ¨ï¼ˆæ±½è½¦ã€ç«è½¦ã€æ­¥è¡Œï¼‰åœ¨çœŸå®ä¸–ç•Œä¸­ä½ç½®æŠ¥å‘Šçš„å‡†ç¡®åº¦ã€‚æˆ‘ä»¬å±•ç¤ºä¸¤ä¸ªç»“æœï¼š1ã€åœ¨metropolitanåŒºåŸŸä¸­èƒ½ä»¥å°äº30ç±³çš„è¯¯å·®è¿½è¸ªä¸€ä¸ªæ­¥è¡Œè·¯å¾„ã€‚2ã€æ ¹æ®è¿‡å»1å‘¨å†…æœ€é«˜çš„ä½ç½®é¢‘ç‡èƒ½æ¨æ–­å‡ºç”¨æˆ·çš„ä½æ‰€æˆ–å…¬å¸ï¼Œè¯¯å·®å¤§çº¦åœ¨10ç±³ã€‚

- We discover a design flaw in OF that lets Apple correlate the location of multiple owners if the same finder submits the reports. This would jeopardize location privacy for all other owners if only a single location became known.

  è®¾è®¡ç¼ºé™·ï¼šåŒä¸€ä¸ªfinderä¸Šä¼ çš„æŠ¥å‘Šä¼šå…³è”å¤šä¸ªç”¨æˆ·ï¼Œåªè¦çŸ¥é“å…¶ä¸­ä¸€ä¸ªä½ç½®ï¼Œåˆ™ä¼šæš´éœ²å…¶ä»–ç”¨æˆ·çš„ä½ç½®ä¿¡æ¯ã€‚

- We discover that a local application on macOS can effectively circumvent Appleâ€™s restrictive location API [5] and access the userâ€™s location history without their consent, allowing for device tracking and user identification.

  macOSçš„ç¨‹åºå¯é«˜æ•ˆåœ°circumvent Appleçš„location APIçš„é™åˆ¶ï¼Œç¼ºä¹ç”¨æˆ·åŒæ„çš„æƒ…å†µä¸‹è®¿é—®ç”¨æˆ·çš„å†å²ä½ç½®ä¿¡æ¯ï¼Œå¯¹è®¾å¤‡è¿›è¡Œè¿½è¸ªå’Œç”¨æˆ·è¯†åˆ«ã€‚

- We open-source our PoC implementation and experimental data (cf. *Availability* section).

  æˆ‘ä»¬å¼€æºäº†æˆ‘ä»¬çš„å®ç°å’Œå®éªŒæ•°æ®ã€‚



### Outline

* Chapter-2 & Chapter-3 provide background information about OF and the involved technology.
* Chapter-4 outlines our adversary model.
* Chapter-5 summarizes our reverse engineering methodology.
* Chapter-6 describes the OF protocols and components in detail.
* Chapter-7 evaluates the accuracy of OF location reports.
* Chapter-8 assesses the security and privacy of Appleâ€™s OF design and implementation.
* Chapter-9 & Chapter-10 report two discovered vulnerabilities and propose our mitigations.
* Chapter-11 reviews related work.
* Chapter-12 concludes this work.



## Background

This section gives a brief introduction to BLE and elliptic curve cryptography (ECC) as they are the basic building blocks for OF. We then cover relevant Apple platform internals.

å¯¹BLEæŠ€æœ¯å’Œæ¤­åœ†æ›²çº¿å¯†ç æŠ€æœ¯è¿›è¡Œç®€å•è¯´æ˜ï¼Œå› ä¸ºä»–ä»¬æ˜¯æ„å»ºOFç³»ç»Ÿçš„åŸºç¡€ã€‚ç„¶åå¯¹Appleå¹³å°ç›¸å…³çš„å†…éƒ¨æ¨¡å—è¿›è¡Œè¯´æ˜ã€‚

### Bluetooth Low Energy

Bluetooth Low Energy (BLE) [19] is designed for small battery-powered devices such as smartwatches and fitness trackers with low data rates. Devices can broadcast BLE advertisements to inform nearby devices about their presence. The maximum BLE advertisement payload size is 31 bytes [19]. Apple heavily relies on custom BLE advertisements to announce their proprietary services such as AirDrop and bootstrap their protocols over Wi-Fi or Apple Wireless Direct Link (AWDL) [21, 36, 48]. OF devices also use BLE advertisements to inform nearby finders about their presence [6].

### Elliptic Curve Cryptography

OF employs elliptic curve cryptography (ECC) for encrypting location reports. ECC is a public-key encryption scheme that uses operations on elliptic curve (EC) over finite fields. An EC is a curve over a finite field that contains a known generator (or base point) G. A private key in ECC is a random number in the finite field of the used curve. The public key is the result of the point multiplication of the generator G with the private key. The result is an Xâ€“Y coordinate on the curve. The NIST P-224 curve [39], which is used by OF [6], provides a security level of 112 bit.

OFç³»ç»Ÿè¿ç”¨äº†ECCç®—æ³•åŠ å¯†ä½ç½®æŠ¥å‘Šã€‚ECCæ˜¯ä¸€ç§å…¬é’¥å¯†ç æŠ€æœ¯that uses operations on elliptic curve (EC) over finite fields. An EC is a curve over a finite field that contains a known generator (or base point) G. A private key in ECC is a random number in the finite field of the used curve. The public key is the result of the point multiplication of the generator G with the private key. The result is an Xâ€“Y coordinate on the curve. The NIST P-224 curve, which is used by OF, provides a security level of 112 bit.

### Apple Platform Internals

We briefly introduce the terms keychain and iCloud as they are relevant for Appleâ€™s OF implementation.

#### Keychain

All Apple operating systems (OSs) use a keychain as a database to store secrets such as passwords, keys, and trusted Transport Layer Security (TLS) root certificates. The keychain is used by sys- tem services such as AirDrop [48] and third-party ap- plications to store login information, tokens, and other secrets. Every keychain item may contain a *keychain access group*. This group is used to identify which ap- plication can access which keychain items. Access poli- cies are implemented via *entitlement* files embedded into signed application binaries. A system process prevents the execution of processes with unauthorized entitle- ments, e.g., a third-party application trying to access a system-owned keychain item. This security mechanism can be disabled on jailbroken iOS devices or by deacti- vating macOS system integrity protection (SIP), which helps extracting keys and secrets used by Appleâ€™s sys- tem services.

#### iCloud

iCloud is an umbrella term for all Apple services handling online data storage and synchroniza- tion via Appleâ€™s servers. All *owner* devices signed in to the same Apple account can synchronize themselves via iCloud. OF uses the iCloud keychain to share rolling advertisement keys across all owner devices. The syn- chronization is required to retrieve and decrypt the lo- cation reports from potential finders on any of the owner devices [4, 35].



## Apple Offline Finding Overview

Apple introduced OF in 2019 for iOS 13, macOS 10.15, and watchOS 6 [10]. OF enables locating Apple devices without an Internet connection and promises to operate in a privacy-preserving manner. In 2020, Apple announced to support third-party BLE-enabled devices to be tracked by the OF network [11] and released a protocol specification for their integration [6]. We found that this public specification is incomplete concerning the overall OF system. Within this paper, we focus on our recovered specification that was partly validated by the accessory specification [6].

2019å¹´ï¼ŒAppleæ¨å‡ºOFç³»ç»Ÿã€‚OFèƒ½å¤Ÿåœ¨æ²¡è”ç½‘çš„æƒ…å†µä¸‹è¿½è¸ªAppleè®¾å¤‡ï¼Œå¹¶æ‰¿è¯ºä»¥ä¿æŠ¤éšç§çš„æ–¹å¼è¿è¡Œã€‚2020å¹´ï¼ŒAppleå®£å¸ƒOFæ”¯æŒè¿½è¸ªä¸‰æ–¹BLEè®¾å¤‡ï¼Œå¹¶ä¸ºä»–ä»¬æä¾›äº†åè®®specã€‚æˆ‘ä»¬å‘ç°è¿™ä¸ªå…¬å¼€çš„specå¯¹äºæ•´ä¸ªOFç³»ç»Ÿæ¥è¯´æ˜¯ä¸å®Œå…¨çš„ã€‚æœ¬è®ºæ–‡ä¸­ï¼Œæˆ‘ä»¬ä¸“æ³¨äºå¤åŸèƒ½ç»å—accessory_specï¼ˆFind_My_network_accessory_protocol_specificationï¼‰éªŒè¯çš„OF_whole_specã€‚

In the following, we give a brief overview of how OF works and introduce the different roles of devices. Fig. 1 depicts the interplay of the roles and protocols involved in OF. 

<img src="find_my_1_overview.png">

In particular, OF involves (1) initial pairing of owner devices, (2) broadcasting BLE advertisements that contain a rolling public key, (3) uploading encrypted location reports to Appleâ€™s servers, and (4) retrieving the location reports on owner devices. The terminology of the roles below has been derived from the official documentation [6].

ä¸Šå›¾ä¸»è¦ä»‹ç»äº†OFç³»ç»Ÿçš„å·¥ä½œæµç¨‹ï¼Œæ¶‰åŠå››ç±»è§’è‰²ä¸å››ç§åè®®

Rolesï¼ˆOwner deviceï¼ŒLost deviceï¼ŒFinder deviceï¼ŒBackend serverï¼‰

Protocolï¼ˆInitial Pairingï¼ŒBroadcasting BLE Advï¼Œuploading & encryptï¼Œretrieving & decryptï¼‰

**Owner devices.** Owner devices share a common Apple ID and can use the *Find My* application on macOS and iOS to search for any devices of the same owner.

**Lost devices.** Devices that determine to be in a lost state start sending out BLE advertisements with a public key to be discovered by finder devices. Apple devices are considered to be lost when they lose Internet connectivity. Third-party accessories [6] are small battery- powered devices that can be attached to a personal item and are set up through an owner device. Accessories determine to be *lost* when they lose their BLE connection to the owner device.

**Finder devices.** Finder devices form the core of the OF network. As of 2020, only iPhones and iPads with a GPS module are offering finder capabilities. Finder devices can discover lost devices and accessories by scanning for BLE advertisements. Upon receiving an OF advertisement, a finder creates an end-to-end encrypted location report that includes its current location and sends it to Appleâ€™s servers.

**Appleâ€™s servers.** Appleâ€™s servers store OF location reports submitted by finder devices. Owner devices can fetch those reports and decrypt them locally.



## Adversary Model

å¯¹æŠ—æ¨¡å‹

OF exposes several interfaces that might be targeted by attackers. In this section, we identify these potentially vulnerable interfaces and devise a comprehensive adversary model that will guide the rest of this paper. We first detail the four sub-models, summarized in Tab. 1, and we specify them by their assumptions, goals, and capabilities following [23]. Then, we motivate the subsequent analysis of OF protocols and components based on these models.

OFæš´éœ²å‡ ä¸ªæ¥å£å¯èƒ½ä¼šæˆä¸ºæ”»å‡»çš„ç›®æ ‡ã€‚æœ¬ç« ï¼Œæˆ‘ä»¬ç¡®å®šäº†è¿™äº›æ½œåœ¨çš„æ˜“å—æ”»å‡»çš„æ¥å£ï¼Œå¹¶è®¾è®¡äº†å…¨é¢çš„å¯¹æŠ—æ¨¡å‹æ¥æŒ‡å¯¼æˆ‘ä»¬çš„åˆ†æã€‚æˆ‘ä»¬é¦–å…ˆç»†åŒ–å››ä¸ªå­æ¨¡å‹å¹¶é€šè¿‡å‡è®¾ã€ç›®æ ‡å’Œèƒ½åŠ›æ¥åˆ†ç±»ä»–ä»¬ã€‚åç»­åŸºäºæ¨¡å‹æ¥è¿›è¡Œå¯¹OFåè®®å’Œç»„ä»¶çš„åˆ†æã€‚æ¨¡å‹å…·ä½“æè¿°å¦‚ä¸‹è¡¨ï¼š

| Model                       | Assumptions                                                  | Goals                                                        | Capabilities                                                 |
| --------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| Local application**ï¼ˆA1ï¼‰** | (1) User-installed application on lost/owner devices that is either reviewed or notarized. <br />(2) Zero-permission. <br />(3) No privilege escalation exploits. | (1) Apple as the service provider. <br />(2) Controls the OF server infrastructure. | (1) Communicate with any server over the Internet. <br />(2) Read/write files that are accessible by the user and not restricted through sandboxing. |
| Proximity-based**ï¼ˆA2ï¼‰**   | (1) In BLE communication range of OF device. <br />(2) Control one or more BLE transceivers to cover a larger area. | (1) Access location of lost devices or personally linkable data. <br />(2) Track lost devices in larger areas (e.g., shopping center or airport). <br />(3) DoS against OF service. | (1) Track devices based on advertisement content. <br />(2) Record and replay advertisements at different locations. <br />(3) Fabricate new adver- tisements. |
| Network-based **ï¼ˆA3ï¼‰**    | (1) MitM position between Apple and OF devices. <br />(2) Cannot break TLS. | (1) Access location of reported lost devices. <br />(2) Identify reported devices. <br />(3) Identify lost devices. | (1) Redirect traffic to a different host. <br />(2) Read, intercept, redirect, or modify traffic. |
| Service operator **ï¼ˆA4ï¼‰** | (1) Apple as the service provider. <br />(2) Controls the OF server infrastructure. | (1) Locate individuals and their lost devices. <br />(2) Correlate locations to create a social graph. | (1) Access to all encrypted OF re- ports and their metadata. <br />(2) Add, remove, or modify reports. |



First of all, we consider adversaries on either of OFâ€™s communication channels (cf. (2)â€“(4) in Fig. 1). In particular, a proximity-based adversary has access to BLE advertisements **(A2)**, and a network-based adversary can modify traffic between OF devices and Appleâ€™s servers **(A3)**. Also, we consider a zero-permission application running with user privileges on an owner/lost device that wants to infer the userâ€™s current location. The application may be distributed inside or outside1 of Ap- pleâ€™s official app stores **(A1)**. Finally, we also consider Apple as the service operator as an adversary that has access to all encrypted location reports and might try to infer any information based on the report metadata such as submission times and finder identifiers **(A4)**. Note that Apple uses its iCloud keychain service for initial device pairing and key synchronization (cf. (1) in Fig. 1). Apple provides detailed information about its keychain [4], which appears to withstand professional forensics analyses [1]. Therefore, we assume that the pairing process is secure throughout this paper.

é¦–å…ˆæˆ‘ä»¬ä¼šæ€è€ƒå¯¹æŠ—ä¼šå­˜åœ¨äºOFçš„äº¤äº’é€šé“ï¼ˆä¹Ÿå°±æ˜¯2~4æ­¥éª¤ in Fig.1ï¼‰ã€‚ç‰¹åˆ«çš„ï¼Œpromixity-basedå¯¹æŠ—èƒ½å¤Ÿè®¿é—®BLEå¹¿æ’­**ï¼ˆA2ï¼‰**ã€‚network-basedå¯¹æŠ—èƒ½å¤Ÿä¿®æ”¹OF devicesä¸Apple's Serverä¹‹é—´çš„traffic**ï¼ˆA3ï¼‰**ã€‚è¿è¡Œåœ¨owner/lost deviceä¸­çš„zero-permissionåº”ç”¨å¸Œæœ›æ¨æ–­å‡ºç”¨æˆ·ç›®å‰çš„ä½ç½®**ï¼ˆA1ï¼‰**ã€‚Apple Serveræä¾›çš„æœåŠ¡å­˜åœ¨ä¸€ç§Service operatorå¯¹æŠ—ï¼Œèƒ½å¤Ÿè®¿é—®æ‰€æœ‰çš„åŠ å¯†ä½ç½®æŠ¥å‘Šï¼Œæ ¹æ®æŠ¥å‘Šçš„Metadataï¼ˆè­¬å¦‚ä¸Šä¼ æ—¶é—´æˆ–è€…finder identifiersï¼‰å¯ä»¥å°è¯•æ¨æ–­ä¸€äº›æœ‰æ„ä¹‰çš„æ¶ˆæ¯**ï¼ˆA4ï¼‰**ã€‚Appleä½¿ç”¨å¥¹çš„keychainæœåŠ¡åšinitial pairingå’Œkey synchronizationã€‚Appleæä¾›äº†ä¸keychainç›¸å…³çš„ç»†èŠ‚ï¼Œç»å—èµ·ä¸“ä¸šçš„forensicsåˆ†æã€‚å› æ­¤ï¼Œæˆ‘ä»¬å‡è®¾pairingè¿‡ç¨‹æ˜¯ç»å¯¹å®‰å…¨çš„ã€‚

To conduct a security and privacy analysis based on these models, we need to understand OF in detail. To this end, we reverse engineer the protocols involved in loosing, finding, and searching devices (cf. (2)â€“(4) in Fig. 1) in Â§ 6. Based on our understanding of OF, we conduct a security and privacy analysis of the BLE communication **(A2)**, the server communication **(A3)**, and storage of encrypted reports and cryptographic keys **(A1/A4)** in Â§ 8.

ä¸ºäº†è¿›è¡Œä¸€åœºåŸºäºè¿™äº›æ¨¡å‹çš„å®‰å…¨å’Œéšç§åˆ†æï¼Œæˆ‘ä»¬éœ€è¦å……åˆ†äº†è§£OFï¼ŒåŒ…æ‹¬ç»†èŠ‚ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¯¹æ¶‰åŠloosingã€findingå’Œsearchingè®¾å¤‡çš„åè®®è¿›è¡Œé€†å‘ã€‚ç„¶ååŸºäºæˆ‘ä»¬å¯¹OFçš„ç†è§£ï¼Œæˆ‘ä»¬è¿›è¡Œå®‰å…¨æ€§ä¸éšç§æ€§çš„åˆ†æã€‚åŒ…æ‹¬ä»¥ä¸‹å‡ ç‚¹ï¼š

* BLE Communication**ï¼ˆA2ï¼‰**
* Server Communication**ï¼ˆA3ï¼‰**
* storage of encrypted reports and cryptographic keys **ï¼ˆA1 / A4ï¼‰**



## Methodology

æ–¹æ³•è®º

Our analysis of OF required a comprehensive understanding of the implemented protocols by Apple. Our methodology follows previous works analyzing the Apple ecosystem [21, 36, 44, 45, 48], while providing new insights into the reverse engineering process. We started this research with the beta releases of macOS 10.15 and iOS 13, the first Apple OSs to support OF. During that time, no official documentation from Apple was available regarding the OF design or implementation. Therefore, we used reverse engineering tools such as system log analysis, static binary analysis, and network traffic analysis. In addition, we implemented an OF prototype to validate our findings. Some of our findings, such as the BLE advertisement format and cryptographic primitives, were later confirmed by Appleâ€™s specification for third-party accessories [6].

æˆ‘ä»¬åˆ†æOFéœ€è¦å¯¹Appleå®ç°çš„åè®®æœ‰å…¨é¢çš„ç†è§£ã€‚æˆ‘ä»¬çš„æ–¹æ³•followsä¹‹å‰å¯¹Appleç”Ÿæ€çš„åˆ†æå·¥ä½œï¼ŒåŒæ—¶ä¸ºé€†å‘å·¥ç¨‹æä¾›æ–°çš„è§†è§’ã€‚æˆ‘ä»¬åœ¨macOS 10.15å’ŒiOS 13å¼€å§‹ç ”ç©¶ï¼Œä»–ä»¬æ˜¯ç¬¬ä¸€ä¸ªæ”¯æŒOFçš„ç‰ˆæœ¬ã€‚æœŸé—´æ²¡æœ‰Appleå¼€æ”¾çš„å…³äºOFè®¾è®¡æˆ–å®ç°çš„å®˜æ–¹æ–‡æ¡£ã€‚å› æ­¤ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†é€†å‘å·¥å…·ï¼ˆç³»ç»Ÿæ—¥å¿—åˆ†æï¼Œé™æ€äºŒè¿›åˆ¶åˆ†æï¼Œç½‘ç»œæ•°æ®åŒ…åˆ†æï¼‰è¿›è¡Œåˆ†æã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å®ç°OF prototypeæ¥éªŒè¯æˆ‘ä»¬çš„å‘ç°ã€‚å…¶ä¸­çš„ä¸€äº›å‘ç°ï¼Œè­¬å¦‚BLEå¹¿æ’­æ ¼å¼å’Œå¯†ç æŠ€æœ¯åŸè¯­ï¼Œéƒ½å¾—åˆ°Appleå®˜æ–¹specçš„ç¡®è®¤ã€‚ã€ŠFind_My_network_accessory_protocol_specificationã€‹

### System Logging

To get a first overview of OS internals, we used the system logging facility on macOS. It aggregates applications and kernel events, and can access the same events from a USB-attached iOS device. We can filter logs by process or keyword and adjust the log level for more verbose output. By using a special configuration profile [27], macOS will show logs that are normally redacted. On iOS, this option is only available with a jailbreak [14].



### Binary analysis

We use binary analysis to understand the closed-source OF protocols. Many Apple binaries have been written in Objective-C, which uses message dispatch to resolve methods at runtime. Therefore, Objective-C binaries include method and instance variable names as part of the dispatch table. This simplifies identifying interesting code paths and segments, e.g., those responsible for parsing BLE packets. Unfortunately, most OF code is written in the newer Swift programming language. Swift methods are statically called by their program address and, therefore, do not require an entry in the symbol table, i.e., the symbol names may be stripped by the compiler. Additionally, the Swift compiler adds several checks to achieve type safety, which clutters the compiled code and makes it hard to follow the program logic. However, dynamically linked frameworks and libraries must keep function names in the symbol table, facilitating the identification of interesting code segments. Furthermore, dynamic analysis methods aid in understanding the control flow and access function parameters at runtime. By hooking functions with a dynamic instrumentation tool such as Frida [40], we can, e.g., access cryptographic keys used by system processes as shown in [45].



### Network analysis

We can identify a serviceâ€™s protocols by monitoring network interfaces, which helps understand the information exchange with external parties. OF uses two protocols: BLE for advertisements and HTTPS for server communication. To understand the embedded custom protocols and payloads, we rely on two sets of tools. For BLE, we use BTLEmap [31] to capture all BLE advertisements. As we already know the basic frame format of Appleâ€™s custom advertisements from related work [21, 36], we were able to identify OF as a new subtype. HTTPS proxies such as [50] decrypt HTTPS sessions by masquerading as both HTTP client and server and using self-signed TLS certificates. To access OF-related traffic, we disabled *certificate pinning*, which OF clients use for all server communication.



## Apple Offline Finding in Detail

This section describes and discusses the technical details of Appleâ€™s OF system. In reference to Fig. 1, we (1) explain the involved cryptography and the key exchange during initial device pairing, and then explain the protocols implementing (2) *losing*, (3) *finding*, (4) *searching* for devices.



In short, devices and accessories in lost mode send out BLE advertisements containing a public key. Finder devices receive them, encrypt their location by using the public key, and upload a report to Appleâ€™s servers. This results in an end-to-end encrypted location report that cannot be read by Apple or any other third-party that does not have access to the ownerâ€™s private keys.



In the following, we explain the cryptography in use, the protocols involved in losing, searching, and finding devices, as well as a brief description of the systemâ€™s implementation on iOS and macOS.



### Cryptography

OF employs ECC [6]. In the following, we explain the key generation and derivation mechanisms and the cryptographic algorithms used for encryption and decryption.

OFç”¨çš„æ˜¯ECCå¯†ç æŠ€æœ¯ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬è§£é‡Šå¯†é’¥çš„ç”Ÿæˆå’Œæ¨å¯¼æœºåˆ¶ï¼Œè¿˜æœ‰åŠ å¯†å’Œè§£å¯†çš„å¯†ç ç®—æ³•ã€‚

**Master Beacon and Advertisement Keys.** Initially, each owner device generates a privateâ€“public key pair (d0,p0) on the NIST P-224 curve and a 32-byte symmetric key SK0 that together form the *master beacon key*. Those keys are never sent out via BLE and are used to derive the rolling advertisement keys included in the BLE advertisements.

ä¸»Beaconå’Œå¹¿æ’­å¯†é’¥ã€‚æœ€åˆçš„Pairingé˜¶æ®µï¼Œowner deviceåŸºäºNIST P-224ç”Ÿæˆä¸€ç»„å…¬ç§é’¥å¯¹ï¼ˆd0ï¼Œp0ï¼‰å’Œä¸€ä¸ª32-byteå¤§å°çš„å¯¹ç§°å¯†é’¥ï¼Œåˆåœ¨ä¸€èµ·å«åšmaster beacon keyã€‚è¿™äº›å¯†é’¥æ˜¯ä¸ä¼šé€šè¿‡BLEæ•£æ’­å‡ºå»ï¼Œä»–ä»¬æ˜¯ç”¨æ¥æ¨å¯¼å‡ºæºå¸¦åœ¨BLEå¹¿æ’­ä¸­çš„rolling public keyã€‚

OF makes device tracking hard by regularly changing the contents of the BLE advertisements. In particular, OF uses the concept of *rolling* keys that can be deterministically derived if one knows the initial input keys (d0,p0) and SK0 but are otherwise unlinkable. OF iteratively calculates the *advertisement keys* (di,pi) for i > 0 as follows using the ANSI X.963 key derivation function (KDF) with SHA-256 [33] and a generator G of the NIST P-224 curve:

SKi =KDF(SKiâˆ’1,â€œupdateâ€,32) (1) 

(ui, vi) = KDF(SKi, â€œdiversifyâ€, 72) (2) 

di = (d0 âˆ— ui) + vi (3) 

pi = di âˆ— G (4)

Equation (1) derives a new symmetric key from the last used symmetric key with 32 bytes length. Equation (2) derives the so-called â€œanti-trackingâ€ keys ui and vi from the new symmetric key with a length of 36 bytes each. Finally, Eqs. (3) and (4) create the advertisement key pair via EC point multiplication using the anti-tracking keys and the master beacon key d0.

OFä¸ºäº†ä¿æŠ¤è®¾å¤‡è¡Œè¸ªï¼Œè®¾è®¡äº†å®šæœŸå˜åŒ–çš„BLEå¹¿æ’­å†…å®¹ã€‚ç‰¹æ®Šçš„ï¼ŒOFä½¿ç”¨äº†rolling keysçš„æ¦‚å¿µï¼Œåªè¦ç¡®å®šå…¬ç§é’¥å¯¹ï¼ˆd0ï¼Œp0ï¼‰å’Œå…±äº«å¯†é’¥sk0ï¼Œå°±å¯ä»¥è¢«æ¨å¯¼å‡ºæ¥ã€‚OFä½¿ç”¨ANSI X.963 å¯†é’¥æ¨å¯¼å…¬å¼ï¼ˆKDFï¼‰å’ŒSHA-256ä¾æ¬¡è®¡ç®—å‡ºBLEå¹¿æ’­çš„å¯†é’¥ï¼ˆdi, piï¼‰ï¼ˆi > 0ï¼‰ã€‚é€šè¿‡ï¼ˆ1ï¼‰~ï¼ˆ4ï¼‰å…±4æ¡å…¬å¼æ¨å¯¼ã€‚

**Key Synchronization.** All owner devices need to access the advertisement keys to download and decrypt location reports. Therefore, OF synchronizes the master beacon keys via iCloud in a property list file encrypted under Advanced Encryption Standard in Ga- lois/Counter Mode (AES-GCM). The decryption key for the file is stored in the iCloud keychain under the label â€œBeacon Store.â€



**Encryption.** The BLE advertisements sent out by a lost device contain an EC public key pi. A finder device that receives such an advertisement determines its current location and encrypts the location with pi. OF employs Elliptic Curve Integrated Encryption Scheme (ECIES) that performs an ephemeral Elliptic Curve Diffie-Hellmann (ECDH) key exchange to derive a shared secret and encrypt the report [37]. In particular, the finderâ€™s encryption algorithm works as follows:



1ã€Generate a new ephemeral key (dâ€² , pâ€² ) on the NIST P-224 curve for a received OF advertisement.

2ã€Perform ECDH using the ephemeral private key dâ€² and the advertised public key pi to generate a shared secret.

3ã€Derive a symmetric key with ANSI X.963 KDF on the shared secret with the advertised public key as entropy and SHA-256 as the hash function.

4ã€Use the first 16 bytes as the encryption key eâ€².

5ã€Use the last 16 bytes as an initialization vector (IV).

6ã€Encrypt the location report under eâ€² and the IV with AES-GCM.



The ephemeral public key pâ€² and the authentication tag of AES-GCM are part of the uploaded message, as shown in Fig. 2. All location reports are identified by an id, which is a SHA-256 hash of pi.

<img src="find_my_2_location_report.png">



**Decryption.** An owner device that retrieves en- crypted location reports follows the inverse of the en- cryption procedure. First, the owner device selects the proper advertisement keys (di,pi) based on the hashed pi of the location report. Second, it performs the ECDH key exchange with the finderâ€™s ephemeral public key pâ€² and the lost deviceâ€™s private key di to compute the sym- metric key eâ€² and the IV. Finally, the owner can use eâ€² and IV to decrypt the location report.



### Losing

ä¸¢å¤±åœºæ™¯

An OF device that loses its Internet connection starts emitting BLE advertisements. This advertisement consists of the 224 bit (28 bytes) public part of the advertisement key (pi), but required some engineering effort to fit in a single BLE packet.

BLEå¹¿æ’­åŒ…æ‹¬28byteså¤§å°çš„å…¬é’¥ï¼ˆè®°ä½œpiï¼‰ï¼ŒæŠŠå¥¹å¡è¿›BLEå¹¿æ’­éœ€è¦ä¸€äº›å·¥ç¨‹æŠ€å·§ã€‚

More precisely, OF only advertises the X coordinate of the public key, which has a length of 28 bytes. The Y coordinate is irrelevant for calculating a shared secret via ECDH, so the sign bit for the compressed format [20] can be omitted.

å‡†ç¡®åœ°è¯´ï¼ŒBLEå¹¿æ’­ä»…ä»…æºå¸¦the X coordinate of the public keyï¼Œå¥¹åˆšå¥½æ˜¯28bytesã€‚å› ä¸ºY coordinateä¸ç”¨ECDHæ¥è®¡ç®—shared secretæ²¡æœ‰å…³ç³»ï¼Œæ‰€ä»¥ä¸ç”¨å¸¦ä¸Šå¥¹ã€‚

**Advertisement Packet Format.** Apple had to engineer its way around the fact that one BLE advertisement packet may contain at most 37 bytes [19, Vol. 6, Part B, Â§ 2.3.1.3], of which 6 bytes are reserved for the advertising MAC address, and up to 31 can be used for the payload. For standard compliance, the custom OF advertisements needs to add a 4-byte header for specifying *manufacturer-specific data*, which leaves 27 bytes. Within this space, Apple uses a custom encoding for subtypes used by other wireless services such as AirDrop [21]), which leaves 25 bytes for OF data. To fit the 28-byte advertisement key in one packet, Apple repurposes the random address field to encode the keyâ€™s first 6 bytes. However, there is one caveat: the BLE standard requires that the first two bits of a random address be set to 0b11. OF stores the first two bits of the advertisement key together with the 24 remaining bytes in the payload to solve the problem. We depict the complete BLE advertisement packet format in Tab. 2. Apple confirmed the reverse-engineered specification later [6].

| Bytes   | Content                                                  |
| ------- | -------------------------------------------------------- |
| 0 - 5   | BLE address ((pi[0] \| (0b11 << 6) \|\| pi[1...5])       |
| 6       | Payload length in bytes (30)                             |
| 7       | Advertisement type (0xFF for manufacturer-specific data) |
| 8 - 9   | Company ID (0x004C)                                      |
| 10      | OF type (0x12)                                           |
| 11      | OF data length in bytes (25)                             |
| 12      | Status (e.g., battery level)                             |
| 13 - 34 | Public key bytes pi[6..27]                               |
| 35      | Public key bits pi[0] â‰« 6                                |
| 36      | Hint (0x00 on iOS reports)                               |



**Advertising Interval.** The same key is emitted during a window of 15 minutes, after which the next key pi+1 is used. During a window, OF-enabled iOS and macOS devices emit one BLE advertisement every two seconds when they lose Internet connectivity.

åŒä¸€ä¸ªkeyåªä¼šå­˜åœ¨15minï¼Œä¹‹åå°±ä¼šè®¡ç®—ä¸‹ä¸ªkeyæ¥å‘å¹¿æ’­ã€‚



### Finding

å‘ç°åœºæ™¯

All finder devices regularly scan for OF advertisements. When the finder receives a packet in the OF advertisement format, it generates and uploads an encrypted location report to Appleâ€™s servers.

æ‰€æœ‰çš„finder devicesä¼šå®šæœŸæ‰«æOF BLEå¹¿æ’­ã€‚å½“find deviceæ”¶åˆ°OFæ ¼å¼çš„BLEå¹¿æ’­æ—¶ï¼Œå¥¹ä¼šç”Ÿæˆå’Œä¸Šä¼ åŠ å¯†ä½ç½®æŠ¥å‘Šåˆ°Apple serverã€‚

**Generating Reports.** The finder parses the public key from the advertisement. Then, it determines its current geolocation and creates a message that includes location, accuracy,3 and status information (cf. green fields in Fig. 2). The message is then encrypted using the algorithm described in Â§ 6.1. Finally, the finder creates a complete location report, including the current timestamp (in seconds since January 1, 2001), the ephemeral public key dâ€², the encrypted message, and the AES-GCM authentication tag as shown in Fig. 2.



**Uploading Reports.** Finder devices accumulate reports over time and upload them in batches regularly, possibly reducing energy and bandwidth consumption. During the evaluation with our test devices, we discovered that the median time from generating to up- loading a location report is 26 min. We include the delay distribution in Appendix B. The delay can increase to several hours if the finder device is in a low power mode [7]. A finder limits the number of uploaded reports for the same advertisement key to four, most likely to prevent excess traffic on Appleâ€™s servers. The upload is implemented as an HTTPS POST request to https://gateway.icloud.com/acsnservice/submit. Every request is authenticated to ensure that only genuine Apple devices can upload requests. Table 3 shows the request header containing a device identity certificate, the signing CAâ€™s certificate, and an Elliptic Curve Digital Signature Algorithm (ECDSA) signature over the request body. The certificates are stored in the deviceâ€™s keychain. However, the private key used for signing is stored in the Secure Enclave Processor (SEP), Appleâ€™s implementation of a trusted execution environment (TEE) [4]. The SEP prohibits the extraction of the signing key but provides an interface for signing requests. We assume that the finder authentication serves as a form of remote attestation. However, we were unable to verify this assumption due to the obfuscated code. The HTTPS request body is prefixed with a fixed header (0x0F8AE0) and one byte specifying the number of included reports. This limits the number of reports in a single request to 255. Each report consists the ID (SHA-256(pi)) followed by the 88-byte location report shown in Fig. 2.

HTTPSç›¸å…³çš„å†…å®¹ï¼ŒRESTful APIè®¾è®¡

| Request Header       | Value                                              |
| -------------------- | -------------------------------------------------- |
| X-Apple-Sign1        | Device identity certificate (base64)               |
| X-Apple-Sign2        | SHA-256 hash of the signing CA (base64)            |
| X-Apple-Sign3        | Device ECDSA signature (ASN.1)                     |
| X-Apple-I-TimeZone   | Clientâ€™s time zone (e.g., GMT+9)                   |
| X-Apple-I-ClientTime | Clientâ€™s time (Unix)                               |
| User-Agent           | â€œsearchpartyd/1 <br />\<iPhoneModel>/\<OSVersion>â€ |



### Searching

æŸ¥æ‰¾åœºæ™¯

An owner requests reported location from Appleâ€™s servers when searching for a lost device. As the advertisement keys are synchronized across all of the ownerâ€™s devices, the owner can use any of their other devices with Appleâ€™s *Find My* app to download and decrypt the location reports. In short, the owner device fetches location reports from Appleâ€™s servers by sending a list of the most recent public advertisement keys of the lost device.

owner deviceå‘é€ä¸€ç»„æœ€è¿‘çš„public keyåˆ°apple serverï¼Œè¯·æ±‚ä½ç½®æŠ¥å‘Š

**Downloading Reports.** Similar to uploading (cf. Â§ 6.4), downloading is implemented as an HTTPS POST request to https://gateway.icloud.com/ acsnservice/fetch. We show the headers in Tab. 4 and a truncated example body in Appendix A. The user authenticates with Appleâ€™s servers using their Apple account in two steps. First, HTTP basic authentication [41] is performed with a unique identifier of the userâ€™s Apple ID4 and a *search-party-token* that is device-specific and changes at irregular intervals (in the order of weeks). Second, several headers with so- called â€œanisette dataâ€ are included. Anisette data are short-lived tokens valid for 30 s and allow omitting two- factor authentication from a previously authenticated system [2].

**Decrypting Reports.** The response to the download request contains a list of finder location reports (cf. Fig. 2) and metadata such as the hashed public advertisement key and the time when the report was uploaded. We show a truncated example of the response body in Appendix A. Using the respective private advertisement keys di, the owner device can then decrypt the received location reports. Appleâ€™s *Find My* application combines a subset of the reports to display the most recent location of the lost device on a map. According to Apple, multiple reports are combined to get a more accurate location [4, p. 104]. While we did not reconstruct Appleâ€™s algorithm, we show in Â§ 7 that the downloaded location reports are sufficient to not only determine the most recent location but to even precisely reconstruct and trace the movement of a lost device.



### System Implementation

Appleâ€™s OF system is implemented across several dae- mons and frameworks which communicate via XPC, Appleâ€™s implementation of interprocess communica- tion [12]. We depict the dependencies of the iOS imple- mentation in Fig. 3. The main daemon that handles OF is *searchpartyd*, which runs with root privileges. It gen- erates the necessary keys and performs all cryptographic operations. The daemon is also responsible for commu- nicating with Appleâ€™s servers to synchronize keys, sub- mit location reports as a finder device, and fetch loca- tion reports as an owner device. The *bluetoothd* daemon is responsible for sending and receiving OF advertise- ments and passes received advertisements to *locationd*. The *locationd* daemon adds the deviceâ€™s current location and forwards this information to *searchpartyd*, which generates the finder reports. On macOS, some function- ality of *searchpartyd* such as the server communication is externalized to the *searchpartyuseragent* daemon to support the multi-user architecture that is not available on iOS.



## Location Report Accuracy

ä½ç½®æŠ¥å‘Šç²¾ç¡®åº¦





## Security and Privacy Analysis

å®‰å…¨å’Œéšç§åˆ†æ

In this section, we perform a security and privacy analysis of Appleâ€™s OF system implemented on iOS and macOS based on the adversary models described in Â§ 4. We first examine the cryptography-related components that are relevant for the local application **(A1)** and service operator **(A4)** models that have access to keys and encrypted reports, respectively. Then, we assess the BLE interface relevant to the proximity-based adversary **(A2)** and the HTTPS-based server communication relevant for the network-based adversary **(A3)**. We summarize our findings in Tab. 8 and discuss in the following.

æ ¹æ®chapter 4çš„å¯¹æŠ—æ¨¡å‹ï¼Œè¿›è¡Œå®‰å…¨ä¸éšç§åˆ†æã€‚æˆ‘ä»¬é¦–å…ˆæµ‹è¯•ï¼ˆA1-local applicationï¼‰ä¸ï¼ˆA2-service operatorï¼‰ï¼Œç„¶åæˆ‘ä»¬è¯„ä¼°ä¸åŸºäºé‚»è¿‘çš„å¯¹æ‰‹ç›¸å…³çš„ BLE æ¥å£ï¼Œè¿˜æœ‰åŸºäºHTTPSçš„ç½‘ç»œå¯¹æŠ—æ¨¡å‹ã€‚æˆ‘ä»¬è¿˜ä¼šæ€»ç»“æˆ‘ä»¬çš„ç»“è®ºåˆ°å¦‚ä¸‹è¡¨æ ¼ï¼š

| Component                  | Potential issue<br />æ½œåœ¨é—®é¢˜                                | exploitable<br />å¯åˆ©ç”¨çš„ | Assessment<br />è¯„ä¼°ç»“è®º                                     |
| -------------------------- | ------------------------------------------------------------ | ------------------------- | ------------------------------------------------------------ |
| Cryptography<br />å¯†ç æŠ€æœ¯ | Key diversification<br />å¯†é’¥å¤šæ ·åŒ–                          | N                         | The custom key diversification process follows the NIST recommendation for key derivation through extraction-then-expansion [16].<br />è‡ªå®šä¹‰å¯†é’¥å¤šæ ·åŒ–è¿‡ç¨‹éµå¾ª NIST å»ºè®®ï¼Œé€šè¿‡**æå–-æ‰©å±•**è¿›è¡Œå¯†é’¥æ´¾ç”Ÿ |
|                            | Choice of P-224 curve<br />P-224æ›²çº¿æ¨¡å‹                     | N                         | Use of NIST P-224 is discouraged by some cryptographers [18]. However, we are unaware of any practical attacks against P-224 when used exclusively for ECDH.<br />ä¸€äº›å¯†ç å­¦å®¶ä¸é¼“åŠ±ä½¿ç”¨ NIST P-224 [18]ã€‚ ç„¶è€Œï¼Œå½“ä¸“é—¨ç”¨äº ECDH æ—¶ï¼Œæˆ‘ä»¬ä¸çŸ¥é“å¯¹ P-224 çš„ä»»ä½•å®é™…æ”»å‡»ã€‚ |
|                            | Insecure key storage<br />éå®‰å…¨å¯†é’¥å­˜å‚¨                     | Yï¼ˆA1ï¼‰                   | Keychains and SEP are used to securely store keys for server communication and the master beacon key. However, macOS caches the derived advertisement keys on disk, which can be read by local applications. Attackers can exploit this to access (historical) geolocation data as we describe in Â§ 10.<br />macOSå°†æ´¾ç”Ÿçš„å¹¿æ’­å¯†é’¥ç¼“å­˜åœ¨ç£ç›˜ä¸Šï¼Œå¯è¢«local applicationè¯»å–åˆ°ï¼Œæ”»å‡»è€…å¯åˆ©ç”¨å†å²è®°å½•ã€‚ |
| Bluetooth<br />è“ç‰™æŠ€æœ¯    | Device tracking via BLE advertisements<br />é€šè¿‡BLEå¹¿æ’­è¿›è¡Œè®¾å¤‡è¿½è¸ª | N                         | BLE payload and address are determined by the advertisement key, which is changed at 15 min intervals, making long-term tracking hard.<br />å› ä¸ºBLE payloadä¸addresséƒ½ä¾èµ–äºrolling keyï¼Œæ¯15minæ¢ä¸€æ¬¡ï¼Œæ‰€ä»¥é¢„é˜²äº†é•¿æœŸè¿½è¸ªã€‚ |
|                            | Remote code execution (RCE)<br />è¿œç¨‹ä»£è¡Œæ‰§è¡Œ                | N                         | As OF uses non-connectable mode to emit advertisements, devices remain secure against RCE attacks on the Bluetooth firmware [42].<br />å› ä¸ºOFä½¿ç”¨çš„æ˜¯ä¸å¯è¿æ¥çš„BLEå¹¿æ’­ï¼Œé¿å…äº†RCEæ”»å‡»ã€‚ |
|                            | Denial-of-service (DoS)<br />æ‹’ç»æœåŠ¡                        | Yï¼ˆA2ï¼‰                   | An attacker could emit/relay legitimate advertisements at other physical locations to **pollute** the set of location reports.<br />æ”»å‡»è€…å¯ä»¥åœ¨å…¶ä»–ç‰©ç†ä½ç½®å‘å‡º/ä¸­ç»§åˆæ³•å¹¿å‘Šä»¥æ±¡æŸ“ä½ç½®æŠ¥å‘Šé›†ã€‚ |
| Server comm.<br />ç½‘ç»œè¿æ¥ | Spoofing (finder)<br />æ¬ºéª—ï¼ˆfinderï¼‰                        | N                         | Impact similar to Bluetooth relaying. However, we have been unable to inject fabricated location reports into the server communication.<br />å½±å“ç±»ä¼¼äºè“ç‰™ä¸­ç»§ã€‚ ä½†æ˜¯ï¼Œæˆ‘ä»¬æ— æ³•å°†ä¼ªé€ çš„ä½ç½®æŠ¥å‘Šæ³¨å…¥æœåŠ¡å™¨é€šä¿¡ã€‚ |
|                            | Spoofing (owner)<br />æ¬ºéª—ï¼ˆownerï¼‰                          | N                         | Spoofing an owner device is not critical as location reports are end-to-end encrypted.<br />æ¬ºéª—æ‰€æœ‰è€…è®¾å¤‡å¹¶ä¸é‡è¦ï¼Œå› ä¸ºä½ç½®æŠ¥å‘Šæ˜¯ç«¯åˆ°ç«¯åŠ å¯†çš„ã€‚ |
|                            | Device identification<br />è®¾å¤‡æ ‡è¯†                          | Yï¼ˆA4ï¼‰                   | Appleâ€™s servers can identify both finder and owner devices. This enables a location correlation attack that we discuss in Â§ 9.<br />Apple çš„æœåŠ¡å™¨å¯ä»¥è¯†åˆ«æŸ¥æ‰¾å™¨å’Œæ‰€æœ‰è€…è®¾å¤‡ã€‚è¿™ä½¿å¾—æˆ‘ä»¬åœ¨ç¬¬ 9 èŠ‚ä¸­è®¨è®ºçš„ä½ç½®ç›¸å…³æ”»å‡»æˆä¸ºå¯èƒ½ã€‚ |



### Cryptography

**Key Diversification.** OF employs key diversification to derive the rolling advertisement keys from the master beacon key (cf. Â§ 6.1). Appleâ€™s design follows the NIST recommendation of performing extraction-then-expansion [16] to securely derive keys. The two-step process first extracts a derivation key from a secure input and then expands this key to the desired output length. Specifically, OF first extracts a new 32-byte key SKi from the previous derivation key using the KDF and then expands SKi using the same KDF to 72 bytes.

**å¯†é’¥å¤šæ ·æ€§**ã€‚OFé‡‡ç”¨Key Diversificationå’ŒMaster Beacon Keyæ´¾ç”Ÿå‡ºRolling Adv Keysã€‚Appleçš„è®¾è®¡éµå¾ªNISTå»ºè®®é€šè¿‡**æå–-æ‰©å±•**è¿›è¡Œå¯†é’¥æ´¾ç”Ÿã€‚å…¶ä¸­**æå–**æ˜¯æŒ‡ä»å®‰å…¨è¾“å…¥ä¸­æå–æ´¾ç”Ÿå¯†é’¥ï¼Œ**æ‰©å±•**æ˜¯æŒ‡å°†æ´¾ç”Ÿå¯†é’¥çš„é•¿åº¦æ‰©å±•åˆ°é¢„æœŸçš„é•¿åº¦ã€‚è¿™é‡Œï¼ŒOFé¦–å…ˆä½¿ç”¨KDF_OFå’ŒSK_i-1**æå–**å‡ºä¸€ä¸ª32-byteçš„å…±äº«å¯†é’¥SK_iï¼Œç„¶åä½¿ç”¨ç›¸åŒçš„KDF_OFå°†SK_i**æ‰©å±•**åˆ°72-byteã€‚

**Choice of NIST P-224 Curve.** We believe that Appleâ€™s choice for the NIST P-224 curve is the consequence of the constrained capacity of BLE advertisements while maximizing the security level of the encryption keys. Appleâ€™s implementation of P-224 in *corecrypto* has been submitted to validate compliance with U.S. Federal Information Processing Standards (FIPS) [9]. Within the cryptography community, some researchers discourage the use of P-224 because its generation process is unclear [17, 18]. More modern curves with the same security margin are available, e.g., M-221 [13], but are not used by Apple. 

**é€‰æ‹©æ›²çº¿NIST P-224**ã€‚Appleä¹‹æ‰€ä»¥é€‰æ‹©P-224è€Œæ²¡æœ‰é€‰æ‹©æ›´é«˜å®‰å…¨æ€§çš„256ï¼Œæ˜¯ç”±äºå—BLEå¹¿æ’­çš„é•¿åº¦é€‰æ‹©ã€‚Apple åœ¨ corecrypto ä¸­çš„ P-224 å®æ–½å·²æäº¤ä»¥éªŒè¯æ˜¯å¦ç¬¦åˆç¾å›½è”é‚¦ä¿¡æ¯å¤„ç†æ ‡å‡† (FIPS)ã€‚åœ¨å¯†ç å­¦ç•Œï¼Œä¸€äº›ç ”ç©¶äººå‘˜ä¸é¼“åŠ±ä½¿ç”¨ P-224ï¼Œå› ä¸ºå®ƒçš„ç”Ÿæˆè¿‡ç¨‹å°šä¸æ¸…æ¥š [17, 18]ã€‚å…·æœ‰ç›¸åŒå®‰å…¨è£•åº¦çš„æ›´ç°ä»£çš„æ›²çº¿å¯ç”¨ï¼Œä¾‹å¦‚ M-221 [13]ï¼Œä½† Apple å¹¶æœªä½¿ç”¨ã€‚

**Insecure Key Storage.** We analyzed how OF keys and secrets are stored on the system. While most in- volved keys are synchronized and stored in the iCloud keychain, we discovered that the advertisement keys de- rived from the master beacon key (cf. Â§ 6.1) are cached on disk to avoid unnecessary re-computations. We found that the cached key directory is accessible by a local ap- plication with user privileges and can be used to bypass the systemâ€™s location API, as we describe in Â§ 10.

macOSæ²¡æœ‰å†…ç½®çš„å®‰å…¨å­˜å‚¨åŒºåŸŸã€‚

### Bluetooth

**Device Tracking.** One of the key design goals of OF is to prevent tracking of lost devices via their BLE advertisements. According to our analysis, OF fulfills this promise by randomizing both BLE advertisement address and payload in 15 min intervals (cf. Â§ 6.2).



**Remote Code Execution.** In addition, OF uses the so-called â€œnon-connectable modeâ€ [19, Vol. 3, Part C, Â§ 9.3.2], which means that other devices cannot connect to it and exploit potential remote code execution (RCE) vulnerabilities in the Bluetooth firmware [42].



**Denial-of-Service Through Relaying.** BLE advertisements only contain the public part of an advertisement key and are not authenticated. Anyone recording an advertisement can replay it at a different physical location. Any finder at that location would generate a location report and submit it to Apple. Through this type of relaying, an attacker could make a lost device appear at a different location, effectively mounting a DoS attack as owners would receive different contradicting location reports.



### Server Communication

**Spoofing.** The communication with Appleâ€™s servers uses TLS, including certificate pinning to ensure that no MitM attack can be deployed. Based on our analysis, the protocol seems to implement a secure authentication scheme. However, we have been unable to reconstruct some of the involved components. We understand that a device-specific certificate (cf. Â§ 6.3) and a private signing key, protected by the SEP, are involved in submitting reports. We *assume* that this private key is used for remote attestation to prevent non-Apple devices from submitting potentially fabricated reports. The genera- tion and registration process of these keys with Appleâ€™s server remains unknown to us. Also, the â€œanisette dataâ€ used for authenticating owner devices (cf. Â§ 6.4) is not publicly documented, and the code that generates the tokens is highly obfuscated.



**Device Identification.** While we did not recover the exact details of the authentication mechanism, we have observed that both finder and owner devices pro- vide identifiable tokens to Appleâ€™s servers. In particular, owner devices provide their Apple ID to access location reports. In Â§ 9, we show that by requesting IDs, Appleâ€™s servers areâ€”in principleâ€”able to correlate the locations of different owners.



## Apple Can Correlate User Locations

Appleå¯ä»¥å…³è”ç”¨æˆ·ä½ç½®

Apple as the service provider **(A4)** could infer that two or more owners have been in close proximity to each other as OF uses identifiable information in both upload and download requests. Law enforcement agencies could exploit this issue to deanonymize participants of (political) demonstrations even when participants put their phones in flight mode. Exploiting this design vulnerability requires that the victims request the location of their devices via the Find My application.6 Next, we describe the vulnerability, a possible attack, and our proposed mitigation.

Appleèƒ½å¤Ÿæ¨æ–­ä¸¤ä¸ªæˆ–å¤šä¸ªownerçš„ä½ç½®å¾ˆé è¿‘ï¼Œå› ä¸ºOFä½¿ç”¨äº†ç›¸åŒçš„identifiable informationä½œä¸ºä¸Šä¼ æ¶ˆæ¯ã€‚å³ä½¿å‚ä¸è€…å°†æ‰‹æœºç½®äºé£è¡Œæ¨¡å¼ï¼Œæ‰§æ³•æœºæ„ä¹Ÿå¯ä»¥åˆ©ç”¨æ­¤é—®é¢˜å¯¹ï¼ˆæ”¿æ²»ï¼‰ç¤ºå¨çš„å‚ä¸è€…è¿›è¡ŒåŒ¿ååŒ–ã€‚åˆ©ç”¨æ­¤è®¾è®¡æ¼æ´éœ€è¦å—å®³è€…é€šè¿‡ Find My åº”ç”¨ç¨‹åºè¯·æ±‚å…¶è®¾å¤‡çš„ä½ç½®ã€‚6 æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†æè¿°è¯¥æ¼æ´ã€å¯èƒ½çš„æ”»å‡»ä»¥åŠæˆ‘ä»¬å»ºè®®çš„ç¼“è§£æªæ–½ã€‚



### Vulnerability

When uploading and downloading location reports, finder and owner devices reveal their identity to Apple. During the upload process, the finder reveals a device-specific identifier in the HTTPS request header (cf. Tab. 3) that can be used to link multiple reports to the same finder. Similarly, during the download process, the owner device has to reveal its Apple ID. In particular, the owner includes its Apple ID in the HTTPS request headers (cf. Tab. 4), which allows Apple to link reports uploaded by a particular finder to the Apple ID of the downloading owners. Since we do not have access to Appleâ€™s servers, we cannot make assumptions about whether or not Apple actually stores such metadata. However, the fact that Apple *could* store this informa- tion indefinitely opens the possibility of abuse.

åœ¨ä¸Šä¼ å’Œä¸‹è½½ä½ç½®æŠ¥å‘Šæ—¶ï¼Œfinderå’Œownerä¼šå‘ Apple é€éœ²ä»–ä»¬çš„èº«ä»½ã€‚åœ¨ä¸Šä¼ è¿‡ç¨‹ä¸­ï¼ŒæŸ¥æ‰¾å™¨ä¼šåœ¨ HTTPS è¯·æ±‚æ ‡å¤´ï¼ˆå‚è§è¡¨ 3ï¼‰ä¸­æ˜¾ç¤ºç‰¹å®šäºè®¾å¤‡çš„æ ‡è¯†ç¬¦ï¼Œè¯¥æ ‡è¯†ç¬¦å¯ç”¨äºå°†å¤šä¸ªæŠ¥å‘Šé“¾æ¥åˆ°åŒä¸€æŸ¥æ‰¾å™¨ã€‚åŒæ ·ï¼Œåœ¨ä¸‹è½½è¿‡ç¨‹ä¸­ï¼Œæ‰€æœ‰è€…è®¾å¤‡å¿…é¡»æ˜¾ç¤ºå…¶ Apple IDã€‚ç‰¹åˆ«æ˜¯ï¼Œæ‰€æœ‰è€…å°†å…¶ Apple ID åŒ…å«åœ¨ HTTPS è¯·æ±‚æ ‡å¤´ä¸­ï¼ˆå‚è§è¡¨ 4ï¼‰ï¼Œè¿™å…è®¸ Apple å°†ç‰¹å®šæŸ¥æ‰¾å™¨ä¸Šä¼ çš„æŠ¥å‘Šé“¾æ¥åˆ°ä¸‹è½½æ‰€æœ‰è€…çš„ Apple IDã€‚ç”±äºæˆ‘ä»¬æ— æ³•è®¿é—® Apple çš„æœåŠ¡å™¨ï¼Œå› æ­¤æˆ‘ä»¬æ— æ³•å‡è®¾ Apple æ˜¯å¦å®é™…å­˜å‚¨äº†æ­¤ç±»å…ƒæ•°æ®ã€‚ç„¶è€Œï¼ŒApple *å¯ä»¥*æ— é™æœŸåœ°å­˜å‚¨è¿™äº›ä¿¡æ¯çš„äº‹å®ä¼šæ— é™æœŸåœ°æ‰“å¼€æ»¥ç”¨çš„å¯èƒ½æ€§ã€‚

â€‹                               Advertise: p1
 F â†âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’ L1

â€‹                               Advertise: p2
 F â†âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’ L2

â€‹    Upload: SHA(p1), Report1, SHA(p2), Report2
 F âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ Apple

â€‹               Download: Apple ID1, SHA(p1)
 O1 âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ Apple

â€‹               Download: Apple ID2, SHA(p2)
 O2 âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ Apple

**Fig. 6.** Apple could infer which users have been in close proximity to each other.



### Attack

It is possible for Apple to find out which owners have been in physical proximity to each other *if the owners request the location of their devices via the Find My application.* We sketch the attack for two owners in Fig. 6. A finder F receives advertisements from the lost devices L1 and L2 that belong to the owners O1 and O2, respectively, and publishes encrypted location reports to Appleâ€™s servers. Due to the limited communication range of BLE, we can reasonably assume that L1 and L2 have been in close proximity if the respective location reports were generated at a similar time and submitted by the same finder. Later, O1 and O2 both download location reports, by opening the *Find My* app, for L1 and L2, respectively. At this point, Apple can infer that these two owners identified by their Apple IDs were close to each other.

å¦‚æœæ‰€æœ‰è€…é€šè¿‡ Find My åº”ç”¨ç¨‹åºè¯·æ±‚å…¶è®¾å¤‡çš„ä½ç½®ï¼ŒApple å¯ä»¥æŸ¥æ˜å“ªäº›æ‰€æœ‰è€…å½¼æ­¤ç‰©ç†æ¥è¿‘ã€‚* æˆ‘ä»¬åœ¨å›¾ 6 ä¸­æç»˜äº†é’ˆå¯¹ä¸¤ä¸ªæ‰€æœ‰è€…çš„æ”»å‡»ã€‚ ä»åˆ†åˆ«å±äºæ‰€æœ‰è€… O1 å’Œ O2 çš„ä¸¢å¤±è®¾å¤‡ L1 å’Œ L2 æ¥æ”¶å¹¿å‘Šï¼Œå¹¶å°†åŠ å¯†çš„ä½ç½®æŠ¥å‘Šå‘å¸ƒåˆ° Apple çš„æœåŠ¡å™¨ã€‚ ç”±äº BLE çš„é€šä¿¡èŒƒå›´æœ‰é™ï¼Œå¦‚æœç›¸åº”çš„ä½ç½®æŠ¥å‘Šæ˜¯åœ¨ç›¸ä¼¼çš„æ—¶é—´ç”Ÿæˆå¹¶ç”±åŒä¸€ä¸ªå‘ç°è€…æäº¤çš„ï¼Œæˆ‘ä»¬å¯ä»¥åˆç†åœ°å‡è®¾ L1 å’Œ L2 å·²ç»éå¸¸æ¥è¿‘ã€‚ éšåï¼ŒO1 å’Œ O2 é€šè¿‡æ‰“å¼€ *Find My* åº”ç”¨ç¨‹åºåˆ†åˆ«ä¸‹è½½ L1 å’Œ L2 çš„ä½ç½®æŠ¥å‘Šã€‚ æ­¤æ—¶ï¼ŒApple å¯ä»¥æ¨æ–­å‡ºè¿™ä¸¤ä¸ªé€šè¿‡ Apple ID è¯†åˆ«çš„æ‰€æœ‰è€…å½¼æ­¤æ¥è¿‘ã€‚

### Impact



The presented attack could be harmful to protesters who put their phones into flight mode to stay anonymous and prevent their devices from showing up during a cell site analysisâ€”which is precisely when the devices would start emitting OF advertisements. Law enforcement agencies could record all the advertised public keys at the demonstration site and ask Apple to provide the Apple IDs of the users that later requested location reports to deanonymize the participants. Such a collusion would be a combination of the proximity-based **(A2)** and service provider **(A4)** adversary models (cf. Â§ 4).

æ‰€æå‡ºçš„æ”»å‡»å¯èƒ½å¯¹å°†æ‰‹æœºç½®äºé£è¡Œæ¨¡å¼ä»¥ä¿æŒåŒ¿åå¹¶é˜²æ­¢å…¶è®¾å¤‡åœ¨èœ‚çªç«™ç‚¹åˆ†ææœŸé—´å‡ºç°çš„æŠ—è®®è€…æœ‰å®³â€”â€”è¿™æ­£æ˜¯è®¾å¤‡å¼€å§‹å‘å°„ OF å¹¿å‘Šçš„æ—¶é—´ã€‚ æ‰§æ³•æœºæ„å¯ä»¥åœ¨æ¼”ç¤ºç°åœºè®°å½•æ‰€æœ‰å®£ä¼ çš„å…¬é’¥ï¼Œå¹¶è¦æ±‚ Apple æä¾›ç”¨æˆ·çš„ Apple IDï¼Œè¿™äº›ç”¨æˆ·åæ¥è¦æ±‚æä¾›ä½ç½®æŠ¥å‘Šä»¥å¯¹å‚ä¸è€…è¿›è¡Œå»åŒ¿ååŒ–ã€‚ è¿™ç§å…±è°‹å°†æ˜¯åŸºäºé‚»è¿‘çš„**(A2)** å’ŒæœåŠ¡æä¾›å•†**(A4)** å¯¹æ‰‹æ¨¡å‹çš„ç»„åˆï¼ˆå‚è§ç¬¬ 4 èŠ‚ï¼‰ã€‚



### Proposed Mitigation



There are two straightforward options to mitigate this attack: remove identifying information from either (1) finder devices or (2) owner devices. We assume that the authentication of the finder provides a form a remote attestation proving that the device isâ€”in factâ€”a genuine Apple device allowed to upload location reports to Appleâ€™s servers. In that case, option (1) is not feasible as the finder has to provide some verifiable information by design. However, we currently see no reason why owner devices have to authenticate to Appleâ€™s servers and provide personally identifiable information, i.e., the Apple ID. We found that any Apple device can request arbitrary location reports, so the authentication appears to be a security-by-obscurity measure and only prevents everyone without access to an Apple device from accessing location reports. Therefore, we recommend option (2) as mitigation and disable authentication for download requests.

æœ‰ä¸¤ä¸ªç®€å•çš„é€‰é¡¹å¯ä»¥å‡è½»è¿™ç§æ”»å‡»ï¼šä» (1) æŸ¥æ‰¾å™¨è®¾å¤‡æˆ– (2) æ‰€æœ‰è€…è®¾å¤‡ä¸­åˆ é™¤è¯†åˆ«ä¿¡æ¯ã€‚ æˆ‘ä»¬å‡è®¾å‘ç°è€…çš„èº«ä»½éªŒè¯æä¾›äº†ä¸€ç§è¿œç¨‹è¯æ˜çš„å½¢å¼ï¼Œè¯æ˜è¯¥è®¾å¤‡å®é™…ä¸Šæ˜¯çœŸæ­£çš„ Apple è®¾å¤‡ï¼Œå…è®¸å°†ä½ç½®æŠ¥å‘Šä¸Šä¼ åˆ° Apple çš„æœåŠ¡å™¨ã€‚ åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œé€‰é¡¹ï¼ˆ1ï¼‰æ˜¯ä¸å¯è¡Œçš„ï¼Œå› ä¸ºå‘ç°è€…å¿…é¡»é€šè¿‡è®¾è®¡æä¾›ä¸€äº›å¯éªŒè¯çš„ä¿¡æ¯ã€‚ ä½†æ˜¯ï¼Œæˆ‘ä»¬ç›®å‰è®¤ä¸ºæ‰€æœ‰è€…è®¾å¤‡æ²¡æœ‰ç†ç”±å¿…é¡»å‘ Apple çš„æœåŠ¡å™¨è¿›è¡Œèº«ä»½éªŒè¯å¹¶æä¾›ä¸ªäººèº«ä»½ä¿¡æ¯ï¼Œå³ Apple IDã€‚ æˆ‘ä»¬å‘ç°ä»»ä½• Apple è®¾å¤‡éƒ½å¯ä»¥è¯·æ±‚ä»»æ„ä½ç½®æŠ¥å‘Šï¼Œå› æ­¤èº«ä»½éªŒè¯ä¼¼ä¹æ˜¯ä¸€ç§éšè”½çš„å®‰å…¨æªæ–½ï¼Œåªä¼šé˜»æ­¢æ— æ³•è®¿é—® Apple è®¾å¤‡çš„æ¯ä¸ªäººè®¿é—®ä½ç½®æŠ¥å‘Šã€‚ å› æ­¤ï¼Œæˆ‘ä»¬å»ºè®®å°†é€‰é¡¹ (2) ä½œä¸ºç¼“è§£æªæ–½å¹¶ç¦ç”¨ä¸‹è½½è¯·æ±‚çš„èº«ä»½éªŒè¯ã€‚



## Unauthorized Access of Location History



We discovered a vulnerability of the OF implementa- tion on macOS that allows a malicious application **(A1)** to effectively circumvent Appleâ€™s restricted location API [5] and access the geolocation of all owner devices without user consent. Moreover, historical location reports can be abused to generate a unique mobility profile and identify the user, as we demonstrate in Â§ 7.

æˆ‘ä»¬åœ¨ macOS ä¸Šå‘ç°äº† OF å®ç°çš„æ¼æ´ï¼Œè¯¥æ¼æ´å…è®¸æ¶æ„åº”ç”¨ç¨‹åº **(A1)** æœ‰æ•ˆåœ°ç»•è¿‡ Apple çš„å—é™ä½ç½® API [5] å¹¶åœ¨æœªç»ç”¨æˆ·åŒæ„çš„æƒ…å†µä¸‹è®¿é—®æ‰€æœ‰æ‰€æœ‰è€…è®¾å¤‡çš„åœ°ç†ä½ç½®ã€‚ æ­¤å¤–ï¼Œæ­£å¦‚æˆ‘ä»¬åœ¨ç¬¬ 7 èŠ‚ä¸­æ¼”ç¤ºçš„é‚£æ ·ï¼Œå¯ä»¥æ»¥ç”¨å†å²ä½ç½®æŠ¥å‘Šæ¥ç”Ÿæˆå”¯ä¸€çš„ç§»åŠ¨é…ç½®æ–‡ä»¶å¹¶è¯†åˆ«ç”¨æˆ·ã€‚

### Vulnerability

Â§ 6 describes that the location privacy of lost devices is based on the assumption that the private part of the advertisement keys is only known to the owner de- vices. The advertisement keys change every 15 minutes and OF supports retrieving location reports from the last seven days, so there is a total of 672 advertise- ment keys per device, for which there exist potential location reports on Appleâ€™s servers. In principle, all of these keys could be generated from the master beacon key (cf. Â§ 6.1) whenever needed. However, Apple de- cided to cache the advertisement keys, most likely for performance reasons. During our reverse engineering ef- forts, we found that macOS stores these cached keys on disk in the directory /private/var/folders/\<Random> /com.apple.icloud.searchpartyd/Keys/\<DeviceId> /Primary/\<IdRange>.keys. The directory is readable by the local user andâ€”in extensionâ€”by any application that runs with user privileges. On iOS, those cache files exist as well, but they are inaccessible for third-party applications due to iOSâ€™s sandboxing mechanism.

<img src="find_my_7_attack_flow.png">



### Attack

We describe the attack flow and explain our PoC imple- mentation, which leads to the attacker gaining access to the location history of the victimâ€™s devices. In the following, we detail the operation of our two-part PoC attack. The steps are referring to Fig. 7.



**Reading Private Keys (Steps 1â€“3).** The victim installs a non-sandboxed malicious application.7 When started, the malicious application runs with user priv- ileges and, therefore, has access to the key cache di- rectory. It can read the advertisement keys from disk (2) and then exfiltrate them to the attackerâ€™s server (3). Apart from starting the application, this process requires no user interaction, i.e., no dialogs requesting disk access are displayed to the user.



**Downloading Location Reports (Step 4).** The *at- tackerâ€™s machine* essentially acts as an owner device (cf. Â§ 6.4) but uses the victimâ€™s keys as input for the HTTPS download request. To download the victimâ€™s lo- cation reports, our PoC needs to access the attackerâ€™s *anisette data* for authenticating the request to Appleâ€™s servers. As we need to link private frameworks and ac- cess the anisette data in our implementation, the at- tackerâ€™s macOS system needs to disable SIP and Ap- ple mobile file integrity (AMFI). Since this device is attacker-owned, this requirement does not limit the ap- plicability of the presented attack. SIP and AMFI are disabled by booting in the macOS recovery mode and running the following terminal commands.



```cmd
csrutil disable
nvram boot-args="amfi_get_out_of_my_way=1"
```

**Decrypting Location Reports (Step 5).** In the fi- nal step, the adversary uses the victimâ€™s private keys to decrypt the location reports.



### Impact

The attack essentially allows any third-party applica- tion to *bypass Appleâ€™s Core Location API* [5] that en- forces user consent before an application can access the deviceâ€™s location. Moreover, the attacker can access the location history of the past seven days of *all* the ownerâ€™s devices. The victim is only required to download and run the application but remains otherwise clueless about the breach. Our analysis has shown that the advertise- ment keys are precomputed for up to *nine* weeks into the future, which allows an adversary to continue download- ing new reports even after the victim has uninstalled the malicious application.



Even though the location reports are not continu- ous, our evaluation in Â§ 7 shows that it is easy to identify the userâ€™s most visited places such as home and work- place. Furthermore, we show that the decrypted location reports can accurately track the victimâ€™s movement of the last seven days.



### Mitigation

As a short-term mitigation, users can disable participat- ing in the OF network to prevent the attack. In addi- tion, we propose three long-term solutions to mitigate the attack: (1) encrypting all cached files on disk store the decryption key in the keychain, (2) restricting access to the cache directory via access control lists, (3) not caching the keys and computing them on-demand. In fact, macOS 10.15.7 includes a mitigation based on option (2), which moved the keys to a new directory that is protected via the systemâ€™s sandboxing mechanism.



## Related Work

We review other crowd-sourced location tracking systems and previous security and privacy analyses of Appleâ€™s ecosystem.

æˆ‘ä»¬é‡æ–°å®¡è§†äº†å…¶ä»–crowd-sourced location tracking systemä¸Appleçš„ecosystemä¹‹é—´çš„å®‰å…¨éšç§åˆ†æã€‚



**Crowd-Sourced Location Tracking.** 

Weller et al. [51] have studied the security and privacy of commer- cial Bluetooth tags (similar to Appleâ€™s definition of *ac- cessories*) sold by multiple vendors. Many of the studied systems provide crowd-sourced location tracking similar to Appleâ€™s OF, allowing users to discover lost devices by leveraging the finder capabilities of other devices. The study discovered several design and implementation is- sues, including but not limited to the use of plaintext lo- cation reports, unauthorized access to location reports, broken TLS implementations, and leaking user data. Based on their findings, Weller et al. [51] propose a novel privacy-preserving crowd-sourced location tracking sys- tem called *PrivateFind*. PrivateFind does not need user accounts and uses end-to-end encrypted location reports with a symmetric encryption key stored on the Blue- tooth finder during the initial setup. In their solution, a finder that discovers a lost Bluetooth tag sends its geolocation to the finder over Bluetooth. The lost de- vice encrypts the location with its symmetric key and returns the encrypted report. The finder then uploads the encrypted location report on behalf of the tag. An owner device that knows the symmetric key can then download and decrypt the location report.



To the best of our knowledge, PrivateFind is the only other privacy-friendly offline device finding system next to OF. Both designs achieve similar privacy goals, such as preventing a third party from learning the loca- tion. The main difference is the way encrypted location reports are generated. OF employs public-key cryptog- raphy, which allows finder devices to generate a loca- tion report upon receiving a single Bluetooth advertise- ment. In PrivateFind, lost devices are actively involved in the generation, which leads to the following prac- tical issues: (1) Lost devices or tags drain their bat- teries quicker as they have to establish Bluetooth con- nections with other devices and perform cryptographic operations. This opens up the door for resource-exhaus- tion attacks where a powerful adversary issues an exces- sive number of encryption requests to the lost devices. (2) The lack of finder attestation would allow an at- tacker to upload fabricated reports as the lost device cannot verify the correctness of the provided location.



**Appleâ€™s Wireless Ecosystem Security and Privacy.**

Previous work analyzed parts of Appleâ€™s wireless ser- vices. Bai et al. [15] investigated the risks of using inse- cure multicast DNS (mDNS) service advertisements and showed that they have been able to spoof an AirDrop receiver identity to get unauthorized access to personal files. Stute, Kreitschmann, and Hollick [46] and Stute et al. [48] reverse engineered the complete AWDL and AirDrop protocols and demonstrated several attacks, including user tracking via AWDL, a DoS attack on AWDL, and a MitM attack on AirDrop. Martin et al. [36] extensively analyzed the content of the BLE adver- tisements for several Apple services. They found sev- eral privacy-compromising issues, including device fin- gerprinting and long-term device and activity tracking. Celosia and Cunche [21] extended this work and discov- ered new ways of tracking BLE devices such as Apple AirPods and demonstrated how to recover user email addresses and phone numbers from BLE advertisements sent by Appleâ€™s Wi-Fi Password Sharing (PWS). Hein- rich et al. [30] found that AirDrop also leaks user phone numbers and email addresses and proposes a new pro- tocol based on private set intersection. Stute et al. [45] investigated the protocols involved in PWS and Appleâ€™s Handoff and found vulnerabilities allowing device track- ing via Handoff advertisements, a MitM attack on PWS, and DoS attacks on both services. While the above works have analyzed other services, we leveraged their methodology for approaching our analysis and reverse engineering work of OF.



## Conclusion

Apple has turned its mobile ecosystem into a massive crowd-sourced location tracking system called OF. In this system, all iPhones act as so-called finder devices that report the location of lost devices to their respec- tive owners. Apple claims to implement OF in a privacy- preserving manner. In particular, location reports are inaccessible to Apple, finder identities are concealed, and BLE advertisements cannot be used to track the owner [35]. We have been the first to challenge these claims and provide a comprehensive security and pri- vacy analysis of OF.



The good news is that we were unable to falsify Appleâ€™s specific claims. However, we have found that OF provides a critical attack surface that seems to have been outside of Appleâ€™s threat model. Firstly, the OF implementation on macOS allows a malicious appli- cation to effectively bypass Appleâ€™s location API and retrieve the userâ€™s location without their consent. By leveraging the historical reports, an attacker is able to identify the userâ€™s most visited location with sub-20m accuracy. Secondly, we believe that Apple has yet to provide a good reason why owner devices need to au- thenticate when retrieving encrypted location reports as it allows Apple to correlate the locations of different Apple users.



We were only able to publish our findings by inten- sively studying the OF system using reverse engineering, which is a very time-consuming process (we started ana- lyzing OF mid-2019). To protect user privacy, we believe that systems handling highly sensitive information such as OF need to be *openly and fully* specified to facilitate *timely* independent analyses. To this end, we urge man- ufacturers to provide not only partial [6] but complete documentation of their systems and release components as open-source software whenever possible, which is al- ready a best practice for cryptographic libraries [9].



### Responsible Disclosure

We disclosed the vulnerability in Â§ 10 on July 2, 2020. On October 5, 2020, Apple informed us that macOS 10.15.7 provides a mitigation for the issue, which was assigned CVE-2020-9986. In addition, we informed Apple about the vulnerability in Â§ 9 on October 16, 2020, and are currently waiting for feedback.



### Availability

We release the following open-source software artifacts as part of the Open Wireless Link project [47]: (1) The PoC implementation that can download and decrypt location reports, which we used for the exploit de- scribed in Â§ 10 (github.com/seemoo-lab/openhaystack). (2) The experimental raw data and evalua- tion scripts to reproduce the results in Â§ 7 (github.com/seemoo-lab/offline-finding-evaluation).



### Acknowledgments

We thank our anonymous reviewers and our shepherd Santiago Torres-Arias for their invaluable feedback. We thank Fontawesome for the vector graphics and Stamen for the map tiles used in our figures. This work has been funded by the LOEWE initiative (Hesse, Germany) within the emergenCITY center and by the German Federal Ministry of Education and Research and the Hessen State Ministry for Higher Education, Research and the Arts within their joint support of the National Research Center for Applied Cybersecurity ATHENE.



# FindMyProtocolSpec

Appleå®˜æ–¹åè®®è§„æ ¼ä¹¦



## Core Concepts

æ ¸å¿ƒå†…å®¹

### Overview

The *Find My Network Accessory Specification* defines how an accessory communicates with Apple devices to help owners locate their accessories privately and securely by using the Find My network.

Find My Network Accessory Specificationå®šä¹‰ï¼šåœ¨Find My networkä¸­ï¼Œaccessoryä¸Apple devicesçš„äº¤äº’æ ¼å¼ï¼Œä¿è¯éšç§ä¸å®‰å…¨çš„å‰æä¸‹ï¼Œä»¥å¸®å¿™ownerè¿½è¸ªåˆ°accessoryçš„ä½ç½®ã€‚

### Find My app

The Find My app is where you locate your Apple devices, share your location with friends and family, and locate all Find My network-enabled accessories. The app displays the location of findable items and includes additional features to protect your devices, such as playing sound, using Lost Mode, and so on. See the Find My webpage for more details.

Find My appå…·ä½“3ä¸ªåŠŸèƒ½ï¼Œæ‰‹æœºè‡ªèº«å®šä½æœåŠ¡ï¼Œåˆ†äº«å®šä½ï¼Œå‘ç°Find My network-enabled accessoryã€‚Appé™¤äº†å¯ä»¥å±•ç¤ºaccessoryçš„ä½ç½®å¤–ï¼Œè¿˜æœ‰ä¸€äº›é¢å¤–çš„ç‰¹æ€§ï¼Œè­¬å¦‚Ringingï¼Œå¼€å…³Lost Modeã€‚

### Transport

The Find My network accessory protocol uses Bluetooth Low Energy (BTLE) as the primary transport to interact with Apple devices.

Find My network accessory protocol ä½¿ç”¨BLEä½œä¸ºé¦–è¦çš„é€šä¿¡é“¾è·¯ã€‚

### Operation

The accessory and the owner Apple device generate a cryptographic key pair after Find My network pairing. The owner Apple device has access to both the private and the public key, and the accessory has the public key.

Accessoryä¸Owneråœ¨ç»è¿‡Find My network pairingåï¼Œä¼šç”Ÿæˆä¸€ä¸ªcryptographic key pairï¼ŒOwneræ‹¥æœ‰private keyå’Œpublic keyï¼ŒAccessoryåªæ‹¥æœ‰public keyã€‚

An accessory subsequently broadcasts a rotating key (derived from the public key) as a low energy Bluetooth beacon. This beacon can be picked up by nearby Apple devices (see Find My network). The Apple devices publish the key received in the Bluetooth beacon, along with its own location encrypted using that same key, to Apple servers. Because the private key is stored only on the owner device, the location information is accessible only to the device owner. The data stored in Apple servers is end-to- end encrypted, and Apple does not have access to any location information.

Accessoryé€šè¿‡BLEå°†rotating keyï¼ˆç”±public keyæ´¾ç”Ÿå‡ºæ¥ï¼‰å¹¿æ’­å‡ºå»ï¼ŒFinderèƒ½å¤Ÿå‘ç°é™„è¿‘çš„accessoryã€‚Finderä»BLEå¹¿æ’­ä¸­retrieveå‡ºpublick keyï¼Œä½¿ç”¨public keyå¯¹è‡ªèº«çš„locationåŠ å¯†ï¼Œå¹¶ä¸Šä¼ åˆ°serverã€‚å› ä¸ºprivate keyåªä¿å­˜åœ¨ownerï¼Œæ‰€ä»¥locationä¿¡æ¯åªä¼šè¢«ownerè§£å¯†ã€‚

### Roles

<img src="protocol_spec_1_roles.png">

#### Owner device

When an accessory is paired with an Apple device through the Find My app, the accessory is associated with the Apple ID on that device. This device and all other Apple devices signed in with the same Apple ID are treated as owner devices. The Find My app on an owner device can be used to locate accessories. An owner device is required for actions such as unpairing the device, firmware update, locate, and so on.



#### Accessory

An *accessory* is the device that implements the Find My network accessory protocol and can be located using the Apple Find My network and servers. The accessory is paired with the Apple ID in use on the owner device.



#### Find My network

The Find My network provides a mechanism to locate accessories by using the vast network of Apple devices that have Find My enabled. When an accessory is detected by a nearby Apple device, the device publishes its own encrypted location as the approximate location of the detected accessory. Reports from more than one Apple device can provide a more precise location. Any Apple device that participates in the Find My network is called a *Finder device*. Participation in the Find My network is a user choice that can be reviewed or changed anytime in Settings.

A *non-owner device* is an Apple device in a Find My network that may connect to the accessory but is not an owner device. (For example, a device might connect in response to a UT alert; see Unwanted tracking detection.)



#### Apple server

Apple server receives encrypted location data from Finder devices and temporarily stores it. Only the owner devices can decrypt and read raw locations from the encrypted data. Apple cannot read this information.



### States

Accessory operations can be described using a state machine with the states listed in this section and transition between them based on interactions with an owner device.

<img src="protocol_spec_2_status.png">

#### Unpaired

The accessory must be in an unpaired state on first startup or before the accessory setup is completed. In this state, the accessory must advertise Find My network service as a primary service in a connectable Bluetooth advertisement (See BTLE advertising). The owner user initiates pairing from an owner device. See Pairing for the pairing procedure.



#### Connected

The accessory must enter connected state after the Find My network pairing successfully completes with the owner device. The owner device may disconnect from the accessory after pairing completes. Once paired, the accessory must not pair with another Apple device for Find My network functions. It must stay paired until it successfully completes the unpairing procedure with the owner device.



The accessory must reenter the connected state from nearby or separated state or whenever an owner device connects to the accessory. The accessory shall support simultaneous connections to two Apple devices on the same iCloud account.



Motion detection and UT protocols are disabled in connected state. When the accessory enters this state, advertising payload is set to the nearby key.



#### Nearby



The accessory must enter the nearby state immediately after it disconnects from an owner device. The accessory shall remain in nearby state for TNEARBY. See Timers and constants.



Motion detection and unwanted tracking detection protocols are disabled in nearby state. When the accessory enters this state, advertising payload is set to the nearby key. See Payload for nearby state for details.



#### Separated



The accessory must enter the separated state under these conditions:

1ã€The accessory is paired and starts up from a reset, power cycle, or other reinitialization procedure.

2ã€The accessory is innear by state and the T_NEARBY time-out has expired.

Motion detection and unwanted tracking detection protocols are enabled in separated state. When the accessory enters this state, advertising payload is set to the separated key. See Payload for separated state for details.



## Requirements



### Cryptography

å¯†ç æŠ€æœ¯

#### Operations

Pairing the accessory with an owner device as well as deriving keys requires the following:

Ownerä¸Accessoryåšpairingæ—¶ï¼Œæ´¾ç”Ÿå‡ºå¿…è¦çš„keysï¼Œå¦‚ä¸‹ï¼š

* A cryptographically secure DRBG (see [NIST Special Publication 800-90A](https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-90Ar1.pdf)) with a reliable source of entropy (see [NIST Special Publication 800-90B](https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-90B.pdf)).

  å…·æœ‰å¯é ç†µæºçš„åŠ å¯†å®‰å…¨ DRBGã€‚

* Modular reduction and addition of big integers.

  å¤§æ•°çš„æ¨¡çš„å‡æ³•ä¸åŠ æ³•ã€‚

* An implementation of the SHA-256 cryptographic hash function.

  SHA-256 åŠ å¯†å“ˆå¸Œå‡½æ•°çš„å®ç°ã€‚

* An implementation of the ANSI x9.63 KDF (see [SEC1, 3.6.1 ANSI X9.63 Key Derivation Function](https://www.secg.org/SEC1-Ver-1.0.pdf)).

* Computations on the NIST P-224 elliptic curve (see [FIPS 186-4, D.1.2.2. Curve P-224](https://nvlpubs.nist.gov/nistpubs/FIPS/NIST.FIPS.186-4.pdf)):
  * Generation of a random scalar in [1, q).
  * Scalar multiplication and point addition.
  * Verification that a point is on the P-224 elliptic curve.

* ECDSA/ECDH over the NIST P-256 elliptic curve (see [FIPS 186-4, D.1.2.3. Curve P-256](https://nvlpubs.nist.gov/nistpubs/FIPS/NIST.FIPS.186-4.pdf) and Pairing for more details).

* AES-128-GCM decryption (see [NIST Special Publication 800-38D](https://nvlpubs.nist.gov/nistpubs/Legacy/SP/nistspecialpublication800-38d.pdf)).



#### Implementation

Cryptographic operations and algorithms must compute on secret values in constant time to defend against timing attacks. Similarly, a secret value (or parts of one) must not be used as a memory offset or as the condition for a branch instruction.

Scalar generation should either use rejection sampling or generate at least 64 more bits than needed so that the bias due to the modular reduction is negligible (see [FIPS 186-4, B.4.1 Key Pair Generation Using Extra Random Bits](https://nvlpubs.nist.gov/nistpubs/FIPS/NIST.FIPS.186-4.pdf) and [B.4.2 Key Pair Generation by Testing Candidates](https://nvlpubs.nist.gov/nistpubs/FIPS/NIST.FIPS.186-4.pdf)). The scalar must not be generated by simply reducing the minimally required number of random bytes modulo q (the order of the base point) because this leads to a biased distribution.

Implementation of the scalar multiplication and point addition on elliptic curves must be safe against timing attacks. An exception may be made when computing on public values; for example, to speed up ECDSA signature verification. A variable-time, double-base scalar multiplication for ECDSA signature verification must not be used to compute primary or secondary keys.

Upon receiving a scalar, it must be checked to be in range [1, q), where q is the order of the base point of the elliptic curve, before continuing with the protocol flow. See Scalar validation.

Upon receiving an elliptic curve point, it must be checked to be on the curve. See Elliptic curve point validation.



#### Endianness and wire format

All elliptic curve points, coordinates, and scalars must be transmitted in big-endian byte order; that is, the most significant bytes are sent first.

Whenever a scalar or a coordinate is the input for an algorithm like SHA-256() or ANSI-X9.63-KDF(), or the output of a function, its byte order is assumed to be big-endian. A point is expected to be formatted in uncompressed ANSI X9.63 format. See [SEC1, 2.3.3 EllipticCurvePoint-to-OctetString Conversion](https://www.secg.org/SEC1-Ver-1.0.pdf).



#### Random scalar generation

Whenever this specification requires generation of a P-224 scalar, follow this process:

1ã€Generate r = 28 random bytes using a cryptographically secure DRBG. See Operations.

2ã€If r >= q - 1, where q is the order of the base point of the P-224 elliptic curve, goto step 1.

3ã€Computes = r + 1 and return s as the new scalar.

Another option to securely generate a P-224 scalar is as follows:

1ã€Generate r = 36 random bytes using a cryptographically secure DRBG. See Operations.

2ã€Compute k = r(mod q-1), where q is the order of the base point of the P-224 elliptic curve.

3ã€Computes = k + 1 and return s as the new scalar.

Whenever this specification requires generation of a P-256 scalar, follow this process:

1ã€Generate r = 32 random bytes using a cryptographically secure DRBG. See Operations.

2ã€If r >= q - 1, where q is the order of the base point of the P-256 elliptic curve, goto step 1.

3ã€Compute s = r + 1 and return s as the new scalar.

Another option to securely generate a P-256 scalar is as follows:

1ã€Generate r = 40 random bytes using a cryptographically secure DRBG. See Operations.

2ã€Compute k = r(mod q-1), where q is the order of the base point of the P-256 elliptic curve.

3ã€Compute s = k + 1 and return s as the new scalar.



#### Scalar validation

Whenever this specification requires validation of a P-224 scalar, follow this process:

1ã€If the given scalar s = 0, reject it as invalid.

2ã€If s >= q, where q is the order of the base point of the P-224 elliptic curve, reject s as invalid.

3ã€Make s a valid scalar.



#### Elliptic curve point validation

Whenever this specification requires validation of a P-224 elliptic curve point, follow this process:

1ã€Check that the length of a point is 57 bytes.

2ã€Decode x and y as big-endian integers in the range[0, 2^224).

3ã€Check that x<p and y<p, where p=2^224 - 2^96 + 1.

4ã€Check that y^2 =x^3 + ax + b, where a = p - 3 and b = 0xb4050a850c04b3abf54132565044b0b7d7bfd8ba270b39432355ffb4.



#### ECDSA signature verification

Whenever this specification requires verification of a P-256 ECDSA signature over a message m:

1ã€Decode the given signature in X9.62 format to obtain two 32-byte big-endian integers r and s

(see [SEC1, C.5 Syntax for Signature and Key Establishment Schemes](https://www.secg.org/SEC1-Ver-1.0.pdf)).

2ã€Check that 0 < r < p and 0 < s < p, where p = 2^256 - 2^224 + 2^192 + 2^96 - 1.

3ã€Compute e = SHA-256(m), where m is the signed message.

4ã€Let z be the |q| left most bits of e, where |q| is the bit length of the group order q.

5ã€Compute u1 = zs^-1 (mod q) and u_2 = rs^-1 (mod q).

6ã€Compute the point(x, y) = u1 â‹… G + u2 â‹… QA, where G is the base point of the P-256 elliptic curve and QA is Appleâ€™s signature verification key.

7ã€If (x, y) is the point at infinity, reject the signature.

8ã€If r = x (mod q), then accept the signature, and if not, reject it.

See Apple server public keys for signature verification key (QA) details.



#### AES-GCM decryption

Whenever this specification requires AES-128-GCM decryption of a message M, given a 128-bit AES key K, follow this process:

1ã€Decode message C in the following way: The first 12 bytes are the initialization vector IV, and the last 16 bytes are the authentication tag T. The bytes in between are the ciphertext C.

2ã€Decrypt cipher text Cas(M,Tâ€™) = AES-128-GCM(K,IV,C) without any additional authenticated data.

3ã€Compare authentication tags T and Tâ€™. Do not abort as soon as a mismatch is found, but report an error only after all bytes have been compared.

4ã€If T =Ì¸ Tâ€™, abort and discard the cipher text.



#### Random generation

Whenever this specification requires generation random values, a cryptographically secure DRBG must be used.



## Advertisements



### BTLE advertising

An accessory that is not Find My network paired shall advertise the Find My network service as a primary service when the user puts the accessory in pairing mode.



After Find My network pairing, the accessory shall advertise the Find My network BTLE payload in the format defined in Table 5-1.

**Table 5-1 BTLE advertising**

| AdvAddress       | Manuf AD Type           | Find My network payload     |
| ---------------- | ----------------------- | --------------------------- |
| PrimaryKey[0..5] | AD Type \|-\| CompanyID | Nearby or separated payload |



The Find My network advertising payloads replaces the AdvA field of the advertising PDU defined by the BT SIG with the first 0 to 5 bytes of the current key. The nearby or separated state of the accessory determines the current key. Most significant bits of byte 0 shall be 0b11, indicating a static device address.



The Find My network advertisement payload shall not contain other data types. An accessory must always advertise the Find My network payloads once every T_ADVINT. The accessory may use another advertising instance to broadcast other data types and services.



The manufacturer AD type is defined by the BT SIG, and the payload indicates that the type is Apple.



**Table 5-2 Manufacturer data**

| Byte | Value  | Description                    |
| ---- | ------ | ------------------------------ |
| 0    | 3      | Length of manufacturer AD type |
| 1    | 0xFF   | Manufacturer data AD type      |
| 2..3 | 0x004C | Apple company ID               |



#### Payload for nearby state

When the accessory is in the nearby state or connected to a paired owner device, the advertising payload format must be as defined in Table 5-3.

**Table 5-3 Payload for nearby state**

| Byte | Value                                                        | Description                                                  |
| ---- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 0    | 0x12                                                         | Apple payload type                                           |
| 1    | 0x02                                                         | Length of payload                                            |
| 2    | Bits 0-1: Reserved<br />Bit 2: Maintained<br />Bits 3-4: Reserved<br />Bit 5: 0b1<br />Bits 6-7: Battery state. | Maintained<br/>Set if owner connected within current key rotation period (15 minutes)<br/>Battery state definition<br/>0 = Full<br/>1 = Medium<br/>2 = Low<br/>3 = Critically low |
| 3    | Bits 0-1: Public key<br />Bits 2-7: Reserved                 | Bits 6â€“7 of byte 0 of the primary key (P_i)                  |



#### Payload for separated state

When the accessory is in the separated state, the advertising payload format must be as defined in Table 5-4.

**Table 5-4 Payload for wild state**

| Byte | Value                                                        | Description                                                  |
| ---- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 0    | 0x12                                                         | Apple payload type                                           |
| 1    | 0x19                                                         | Length of payload                                            |
| 2    | Bits 0-1: Reserved<br />Bit 2: Maintained<br />Bits 3-4: Reserved<br />Bit 5: 0b1<br />Bits 6-7: Battery State | Maintained<br/>Set if owner connected within current key rotation period (15 minutes)<br/>0 = Full<br/>1 = Medium<br/>2 = Low<br/>3 = Critically low |
| 3-24 | Separated public key                                         | Bytes 6â€“27 of the Public Key, P_i or PW_j depending on accessory state. See Nearby to separated, Sep- arated to separated, and After power cycle for pos- sible separated state transitions. |
| 25   | Bits 0â€“1: Public key<br />Bits 2â€“7: Reserved                 | Bits 6â€“7 of byte 0 of the public key (P_i or PW_j)           |
| 26   | Hint                                                         | Byte 5 of the Bluetooth address of the current primary key P_i |



## Pairing and Key Manager

### Overview

An accessory must be paired to an owner device before it can be locatable. An owner device will initiate the standard BTLE encryption before it accesses the Find My network services.



<img src="protocol_spec_3_pairing.png">



### Pairing

Find My network pairing is initiated by the owner device using the pairing control point procedures. When an accessory pairs, it must not expose the Find My network pairing control point and it must respond to any of the pairing control point procedures with an invalid_command error message.



An accessory will not be able to Find My network pair if it is paired to an owner device with a different Apple ID.



#### Pairing mode

The accessory must require explicit user intent to enable the Find My network pairing mode. When the user initiates the Find My network pairing mode, the accessory must advertise the Find My network service as a primary service. See Find My network service. The accessory must exit the pairing mode after a time-out.



#### Generate pairing data

Upon establishing standard BLE encrypted pairing session, the accessory must generate collaborative commitment (C1) to start the pairing process and generate per pairing session encryption key seed (SeedK1). See Random generation for the generation of SeedK1. The accessory must regenerate SeedK1 for every new pairing session.

See Collaborative key generation for C1 details.

See Send pairing data pairing control point for details.



#### Send pairing data

The accessory must send encrypted payload generated using Apple server encryption key (Q_E). 

The parameters listed in Table 6-1 are included in generating E2. See ECIES Encryption for E2 generation.



**Table 6-1 Payload to generate E2**

| Key                 | Data type | Size(octets) | Description                                                  |
| ------------------- | --------- | ------------ | ------------------------------------------------------------ |
| SessionNonce        | bytes     | 32           | Nonce generated by Apple device                              |
| C1                  | bytes     | 32           | Data sent by the accessory as initial commitment for pair- ing (see Collaborative key generation for C1 details) |
| Software auth token | bytes     | 1024         | Software authentication token thatâ€™s vended by Apple for each accessory |
| Software auth UUID  | bytes     | 16           | Accessory UUID thatâ€™s associated with software auth          |
| Serial Number       | bytes     | 16           | Accessory serial number                                      |
| Product ID          | String    | 16           | Accessory product ID                                         |
| Vendor ID           | String    | 16           | Accessory vendor ID                                          |
| FW version          | String    | 4            | Accessory firmware version                                   |
| E1                  | bytes     | 89           | Encrypted blob generated by owner device                     |
| SeedK1              | bytes     | 16           | Per pairing session seed for encryption key                  |



#### Finalize pairing

The owner device initiates the finalize pairing process to complete pairing. See Finalize pairing for details.



#### Validate and confirm pairing

The accessory must validate the Apple server signature (S2) using an Apple server signature verification key (Q_A) in order to finalize pairing.

The parameters listed in Table 6-2 are included in generating S2.

**Table 6-2 Payload to generate signature message for S2 verification**

| Key                | Data type | Size(octets) | Description                                                  |
| ------------------ | --------- | ------------ | ------------------------------------------------------------ |
| Software auth UUID | bytes     | 16           | Accessory UUID thatâ€™s associated with software token         |
| SessionNonce       | bytes     | 32           | Nonce generated by owner device                              |
| SeedS              | bytes     | 32           | Unique server seed for each accessory thatâ€™s paired          |
| H1                 | bytes     | 32           | Compute H1=SHA-256(C2)                                       |
| E1                 | bytes     | 89           | Encrypted blob generated by owner device                     |
| E3                 | bytes     | 1052         | Encrypted software token thatâ€™s vended by Apple server for each accessory |



In case of signature verification failure, the accessory must abort pairing. See Send Pairing Status for more details about success and error status.

If Apple server signature verification is successful, then the accessory must decrypt Apple server encrypted blob (E3) using per pairing session symmetric AES 128-bit key (K1).

See derivation of the Pairing Session Key K1 for details on obtaining K1. See AES-GCM decryption for E3 decryption details.

If S2 verification and E3 decryption are successful, then the accessory must store a new software token from E3 and generate a collaborative key (C3) as an acknowledgement to confirm pairing.

The accessory must always use the latest (renewed) software token for any subsequent operations that require authentication with Apple servers (for example, unpair).

See Collaborative key generation for C3 details. See Finalize pairing for E3 details.



#### Send pairing status

After successful pairing, the accessory must go into nearby state and send an acknowledgement to the owner device to confirm the pairing.

The accessory must initialize a 64-bit counter to 0. This counter is used along with the serial number in the NFC payload.

In case of pairing error, the accessory must abort pairing and send a pairing error code. For both success and error, the accessory must generate an encrypted blob (E4) and send it to the owner device.

The payload parameters listed in Table 6-3 are included in generating E4. See ECIES Encryption for E4 generation.



**Table 6-3 Payload to generate E4**

| Key                | Data type | Size(octets) | Descriptions                                         |
| ------------------ | --------- | ------------ | ---------------------------------------------------- |
| Software auth UUID | bytes     | 16           | Accessory UUID thatâ€™s associated with software token |
| Serial Number      | bytes     | 16           | Accessory serial number                              |
| SessionNonce       | bytes     | 32           | Nonce generated by the owner device                  |
| E1                 | bytes     | 89           | Encrypted blob generated by the owner device         |
| Software token     | bytes     | 1024         | Latest Software token                                |
| Status             | bytes     | 4            | Success/failure status code                          |
| OpCode             | bytes     | 4            | Context, value =â€œAckâ€                                |

Pairing error codes will be provided in an updated developer preview. See Send pairing status for details.



### Key management

#### Key definitions

As part of a successful pairing flow, the accessory and the owner device will collaboratively generate both of the following:

* A master public key, P
* Two symmetric keys, SK_N and SK_S



A derivative of the public key P will be broadcast over BTLE. Finder devices can use it to encrypt their current location and provide it to Apple servers for the accessory owner to download and decrypt.



Additionally, the accessory and the server generate a shared secret. The shared secret is used to derive a key and protects requests related to obtaining lost mode information:

* Secret shared with server: ServerSharedSecret

* Symmetric key for pairing session: K1

* Symmetric key for queries with serial number: KS_N



#### Key sequences and rotation policy

The accessory must generate public key sequences with different key rotation intervals, referred to as primary and secondary keys.

* P and SK_N are used to derive the primary key (P_i), which rotates every 15 minutes.

* P and SK_S are used to derive the secondary key (PW_j), which rotates every 24 hours (that is, after every 96 iterations of primary key P_i).



#### Bluetooth advertisement key selection policy

##### After pairing

The accessory must use the primary key P_i (where i=1) as a BTLE advertisement and enters nearby state. See Payload for nearby state for details.



##### Nearby to nearby state transition

If at the end of period â€˜iâ€™ the accessory is still in nearby state, it must use the next primary key P_i+1 (where â€˜iâ€™ is the last primary key index) as a BTLE advertisement. See Payload for nearby state for details.



##### Nearby to separated state transition

When the accessory switches to separated state, it must continue to use the current primary key P_i as a BTLE advertisement until the end of the current separated key period (4 a.m. local time). See Payload for separated state for details.



##### Separated to separated state transition

If at the end of the current separated key period (4 a.m. local time) the accessory is still in separated state, and it was previously advertising the last primary key Pi right after the state transition, it must compute j=i/96+1 and the secondary key PWj and use the latter as a BTLE advertisement.



If at the end of the current separated key period (4 a.m. local time) the accessory is still in separated state, and it was previously advertising the secondary key PWj, it now must use the next secondary keyPWj+1 asaBTLEadvertisement.SeePayloadforseparatedstatefordetails.



##### After power cycle

The accessory must compute j=i/96+1 and the secondary key PWj (where â€˜iâ€™ is the current primary key index) and use the latter as a BTLE advertisement. See Payload for separated state for details.



#### Key schedule definitions

a || b denotes concatenation of the values a and b.

G is the base point of the NIST P-224 elliptic curve. See FIPS 186-4, D.1.2.2. Curve P-224.

q is the order of the base point G. x(P) denotes the x coordinate of the elliptic curve point P.

ANSI-X9.63-KDF(Z, sharedInfo) denotes the KDF described by SEC1, 3.6.1 ANSI X9.63 Key Derivation Function. Z is the secret value (the input key material) and sharedInfo is data shared between the two parties.

Random values and scalars must be generated using a cryptographically secure DRBG. See Operations.



##### Collaborative key generation

As part of the pairing flow, the owner device and the accessory must collaboratively generate a public key P and two symmetric keys, SK_N and SK_S.



1ã€The accessory generates a P-224 scalar s (see Random scalar generation) and a 32-byte random value r. It sends the value C1 = SHA-256(s || r), where len(C1) = 32 bytes, to the owner device. (See Send pairing data.)



2ã€TheownerdevicegeneratesaP-224scalarsâ€™(seeRadomScalarGeneration)anda32-byte random value râ€™. It computes Sâ€™ = sâ€™ â‹… G and sends C2 = {Sâ€™, râ€™}, where len(C2) = 89 bytes, to the accessory. (See Finalize pairing.)



3ã€TheaccessorychecksSâ€™andabortsifitisnotavalidpointonthecurve.(SeeEllipticcurvepoint validation.) It computes the final public key P = Sâ€™ + s â‹… G and sends C3 = {s, r}, where len(C3) = 60 bytes, to the owner device. (See Send pairing status.)



4ã€TheownerdeviceabortsifsisnotavalidP-224scalar(seeScalarvalidation)orifC1=Ì¸ SHA-256(s || r). It computes the final public key P = Sâ€™ + s â‹… G and the private key d = s + sâ€™ (mod q).



5ã€BoththeownerdeviceandtheaccessorycomputethefinalsymmetrickeysSKNandSKSasthe 64-byte output of ANSI-X9.63-KDF(x(P), r || râ€™), where SKN is the first 32 bytes and SKS is the last 32 bytes.



##### Derivation of primary and secondary keys

The accessory must derive primary and secondary keys from the public key P generated at pairing time. P itself must never be sent out and must be stored in a secure location.



For a given 15-minute period i:



1ã€Derive SKNi = ANSI-X9.63-KDF(SKNi-1, â€œupdateâ€), where SKN0 is the SKN as agreed upon at pairing time.



2ã€Derive AT_i = (ui, vi) = ANSI-X9.63-KDF(SKN_i,â€œdiversifyâ€) where len(AT_i) = 72 bytes and len(ui) = len(vi) = 36 bytes.



3ã€Reduce the 36-byte values ui,vi into valid P-224 scalars by computing the following:

* a.ui = ui (mod q-1) + 1
* b.vi = vi (mod q-1) + 1



4ã€Compute Pi =ui â‹…P +vi â‹…G.



Secondary keys are generated as shown above, using period j instead of i and SKS instead of SKN. The result will then be called PWj instead of Pi.



##### Derivation of link encryption key LTKi

The Find My network key generation algorithm generates LTKs, rotating every 15 minutes. The accessory shall use the LTK that corresponds to the current key period as the LTK to encrypt the link on connection to the owner device. A paired owner device also picks the same LTK to encrypt the link. If the device is not a paired Apple device or if the LTK results in a failed encryption, the accessory must disconnect.



The accessory must derive a new link encryption key LTKi for every 15-minute period i. If the paired owner device is nearby, it can use this key to establish a Bluetooth connection and encrypt the link.



For a given 15-minute period i:

1ã€Derive the symmetric key SKNi = ANSI-X9.63-KDF(SKNi-1, â€œupdateâ€), where SKN0 is the symmetric key SKN as agreed upon at pairing time.



2ã€Derive the Intermediate key IKi = ANSI-X9.63-KDF(SKNi, â€œintermediateâ€), where len(IKi) = 32 bytes.



3ã€Derive the Link Encryption key LTKi = ANSI-X9.63-KDF(IKi, â€œconnectâ€), where len(LTKi) = 16 bytes.



##### Derivation of command key CKi

The accessory must derive a new command key CKi for every 15-minute period i. The paired owner device uses CKi to ensure the authenticity of commands sent to the accessory.



For a given 15-minute period i:



1ã€Derive the symmetric key SKNi = ANSI-X9.63-KDF(SKNi-1, â€œupdateâ€), where SKN0 is the symmetric key SKN as agreed upon at pairing time.



2ã€Derive the Intermediate key IKi = ANSI-X9.63-KDF(SKNi, â€œintermediateâ€), where len(IKi) = 32 bytes.



3ã€Derive the command key CKi = ANSI-X9.63-KDF(IKi, â€œcommandâ€), where len(CKi) = 32 bytes.



##### Derivation of the Nearby AuthTokeni

The accessory and owner device will derive a new NearbyAuthTokeni for a given 15-minute period i. The paired owner device broadcasts with an advertising address derived from the NearbyAuthTokeni. An accessory in separated state must switch to nearby state upon detecting such a broadcast.



For a given 15-minute period i:

1ã€Derive the primary key Pi as shown in Derivation of primary and secondary keys.



2ã€Derive the command key CKi as shown in Derivation of command key CKi.



3ã€Denote x(Pi) as the x-coordinate of the primary key Pi, where x(Pi) is represented as a 28-byte big-endian integer.



4ã€Compute NOATi = HMAC-SHA256(CKi, x(Pi) || â€œNearbyAuthTokenâ€).



5ã€Compute Nearby AuthToken_i = MostSignificant6Bytes(NOAT_i)



##### Derivation of ServerSharedSecret

Upon successful pairing, the accessory must generate and retain ServerSharedSecret, where ServerSharedSecret is a 32-byte shared secret:

ServerSharedSecret = ANSI-X9.63-KDF(SeedS || SeedK1, â€œServerSharedSecretâ€)



##### Derivation of the pairing session key K1

To generate the NFC tap payload, KSN must be generated as follows, where K1 is a 16-byte symmetric key:

K1 = ANSI-X9.63-KDF(ServerSharedSecret, â€œPairingSessionâ€)



##### Derivation of the serial number protection key

To generate the NFC tap payload, KSN must be generated as follows, where KSN is a 16-byte symmetric key:



KSN = ANSI-X9.63-KDF(ServerSharedSecret, â€œSerialNumberProtectionâ€)



### Unpair

Unpair action is initiated by the paired owner device to delete Find My network data.

See Unpair for the unpair procedure. See Factory reset for details on resetting the accessory.
